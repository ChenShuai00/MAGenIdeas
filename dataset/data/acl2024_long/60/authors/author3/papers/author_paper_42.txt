{
    "id": "53edcfe4498400cc2cb04e162a7bc61543504d04",
    "title": "A Closer Look at Few-Shot Crosslingual Transfer: Variance, Benchmarks and Baselines",
    "abstract": "We present a focused study of few-shot crosslingual transfer , a recently proposed NLP scenario: a pretrained multilingual encoder is \ufb01rst \ufb01netuned on many annotations in a high resource language (typically English), and then \ufb01netuned on a few annotations (the \u201cfew shots\u201d) in a target language. Few-shot transfer brings large improvements over zero-shot transfer. However, we show that it inherently has large variance and it is necessary to report results on multiple sets of few shots for stable results and to guarantee fair comparison of different algorithms. To address this problem, we publish our few-shot sets. In a study of why few-shot learning outperforms zero-shot transfer, we show that large models heavily rely on lexical hints when \ufb01netuned on a few shots and then over\ufb01t quickly. We evaluate different methods that use few-shot annotations, but do not observe signi\ufb01cant improvements over the baseline. This calls for better ways of utilizing the few-shot annotations."
}