{
    "id": "74e0fd858b07b929ddcd52d0ae9b9d0f87c82a55",
    "title": "Promptable Game Models: Text-guided Game Simulation via Masked Diffusion Models",
    "abstract": "Neural video game simulators emerged as powerful tools to generate and edit videos. Their idea is to represent games as the evolution of an environment\u2019s state driven by the actions of its agents. While such a paradigm enables users to play a game action-by-action, its rigidity precludes more semantic forms of control. To overcome this limitation, we augment game models with prompts specified as a set of natural language actions and desired states. The result\u2014a Promptable Game Model (PGM)\u2014makes it possible for a user to play the game by prompting it with high- and low-level action sequences. Most captivatingly, our PGM unlocks the director\u2019s mode, where the game is played by specifying goals for the agents in the form of a prompt. This requires learning \u201cgame AI,\u201d encapsulated by our animation model, to navigate the scene using high-level constraints, play against an adversary, and devise a strategy to win a point. To render the resulting state, we use a compositional NeRF representation encapsulated in our synthesis model. To foster future research, we present newly collected, annotated and calibrated Tennis and Minecraft datasets. Our method significantly outperforms existing neural video game simulators in terms of rendering quality and unlocks applications beyond the capabilities of the current state-of-the-art. Our framework, data, and models are available at snap-research.github.io/promptable-game-models."
}