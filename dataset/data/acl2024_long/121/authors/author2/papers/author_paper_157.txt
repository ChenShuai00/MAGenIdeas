{
    "id": "15608720c1975b5b4674a231726b4246ee1809d5",
    "title": "A complexity framework for combination of classifiers in verification and identification systems",
    "abstract": "In this thesis we have developed a classifier combination framework based on the Bayesian decision theory. We study the factors that lead to successful classifier combination and identify the scenarios that can benefit from specific combination strategies. The classifier combination problem is viewed as a second-level classification task where the scores produced by classifiers can be taken as features. Thus any generic pattern classification algorithm (neural networks, decision trees and support vector machines) can be used for combination. However, for certain classifier combination problems such algorithms are not applicable, or lead to performance which is worse than specialized combination algorithms. By identifying such problems we provide an insight into the general theory of classifier combination. We introduce a complexity categorization of classifier combinations, which is used to characterize existing combination approaches, as well as to propose new combination algorithms. \nWe have applied our proposed theory to identification systems with large number of classes as is often the case in biometric applications. Existing approaches to combination for such systems use only the matching scores of one class to derive a combined score for that class. We show both theoretically and experimentally that these approaches are inferior to methods which consider the output scores corresponding to all the classes. We introduce the identification model which accounts for the relationships between scores output by one classifier during a single identification trial. This allows the construction of combination methods which consider a whole set of scores output by classifiers in order to derive a combined score for any one class. We also explore the benefits of utilizing the knowledge of classifier independence in combination methods."
}