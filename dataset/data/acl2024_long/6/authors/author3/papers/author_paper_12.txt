{
    "id": "e103287531a9bc7d08acebd8cd1cafa939978154",
    "title": "Faster Hyperparameter Search on Graphs via Calibrated Dataset Condensation",
    "abstract": "Dataset condensation aims to reduce the computational cost of training multiple 1 models on a large dataset by condensing the training set into a small synthetic 2 one. State-of-the-art approaches rely on matching the gradients between the real 3 and synthetic data and are recently applied to condense large-scale graphs for 4 node classification tasks. Although dataset condensation may be efficient when 5 we need to train multiple models for hyperparameter optimization, there is no 6 theoretical guarantee on the generalizability of the condensed data, and it can gen-7 eralize poorly across hyperparameters/architectures in practice; while on graphs, 8 we find and prove this overfitting is much more severe. This paper considers a 9 different condensation objective specifically for hyperparameter search. We aim 10 to generate the synthetic dataset so that the validation-performance ranking of 11 different models under different hyperparameters on the condensed and original 12 datasets are comparable. We propose a novel hyperparameter-calibrated dataset 13 condensation ( HCDC ) algorithm, which learns the synthetic validation data by 14 matching the hyperparameter gradients computed by implicit differentiation and 15 efficient inverse Hessian approximation. HCDC employs a supernet with dif-16 ferentiable hyperparameters, making it suitable for modeling GNNs with widely 17 different convolution filters. Experiments demonstrate that the proposed framework 18 effectively maintains the validation-performance rankings of GNNs and speeds up 19 hyperparameter/architecture search on graphs. 20"
}