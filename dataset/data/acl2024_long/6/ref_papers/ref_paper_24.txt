{
    "id": "848e690a62c327e1210532d58a6b914097cac763",
    "title": "On the Hidden Mystery of OCR in Large Multimodal Models",
    "abstract": "Large models have recently played a dominant role in natural language processing and multimodal vision-language learning. It remains less explored about their ef\ufb01cacy in text-related visual tasks. We conducted a comprehensive study of existing publicly available multimodal models, evaluating their performance in text recognition, text-based visual question answering, and key information extraction. Our \ufb01ndings reveal strengths and weaknesses in these models, which primarily rely on semantic understanding for word recognition and exhibit inferior perception of individual character shapes. They also display indifference towards text length and have limited capabilities in detecting \ufb01ne-grained features in images. Consequently, these results demonstrate that even the current most powerful large multimodal models cannot match domain-speci\ufb01c methods in traditional text tasks and face greater challenges in more complex tasks. Most importantly, the baseline results showcased in this study could provide a foundational framework for the conception and assessment of innovative strategies targeted at enhancing zero-shot multimodal techniques. Evaluation pipeline will be available at https://github.com/Yuliang-Liu/MultimodalOCR ."
}