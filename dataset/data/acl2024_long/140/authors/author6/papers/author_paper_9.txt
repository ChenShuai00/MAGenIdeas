{
    "id": "4bee75d940caa0db0d4b08fb6ee8190ad39f721e",
    "title": "What is \u201cWhere\u201d: Physical Reasoning Informs Object Location",
    "abstract": "Abstract A central puzzle the visual system tries to solve is: \u201cwhat is where?\u201d While a great deal of research attempts to model object recognition (\u201cwhat\u201d), a comparatively smaller body of work seeks to model object location (\u201cwhere\u201d), especially in perceiving everyday objects. How do people locate an object, right now, in front of them? In three experiments collecting over 35,000 judgements on stimuli spanning different levels of realism (line drawings, real images, and crude forms), participants clicked \u201cwhere\u201d an object is, as if pointing to it. We modeled their responses with eight different methods, including both human response-based models (judgements of physical reasoning, spatial memory, free-response \u201cclick anywhere\u201d judgements, and judgements of where people would grab the object), and image-based models (uniform distributions over the image, convex hull, saliency map, and medial axis). Physical reasoning was the best predictor of \u201cwhere,\u201d performing significantly better than even spatial memory and free-response judgements. Our results offer insight into the perception of object locations while also raising interesting questions about the relationship between physical reasoning and visual perception."
}