{
    "id": "c85c7c11db692572a2c1267929dd9ba43613c8ba",
    "title": "Absorbing Commonsense Knowledge from LLMs for Improving Social Fairness in Pre-trained Language Models",
    "abstract": "Pre-trained Language models (PLMs) are 001 trained on inherently socially biased sources, 002 inevitably causing undesirable application im-003 pacts. Current debiasing paradigm involves 004 identifying bias from external corpora, which 005 have limited quality, diversity, or equivalence 006 among different groups, potentially impacting 007 bias location and debiasing effectiveness. In 008 light of this, we advance fairness in PLMs by 009 absorbing coherent, balanced, and semantically 010 informative social Commonsense Knowledge 011 (CK-Debias) automatically generated from 012 large language models (LLMs). Our study ad-013 dresses the demographic CK generation from 014 LLM and explores strategies to optimize CK 015 utilization. This is achieved by employing 016 causal analysis to align knowledge for estimat-017 ing bias space and identifying the most biased 018 prompts to enhance bias avoidance capabil-019 ity. Experiment results on public datasets and 020 intrinsic and extrinsic metrics show that CK-021 Debias can significantly reduce multiple social 022 biases across various PLMs while keeping their 023 language expressiveness intact. 024"
}