{
    "id": "62877098e34d5783960ac02ac8b76dbe729ea174",
    "title": "In-Context Learning of Large Language Models Explained as Kernel Regression",
    "abstract": "Large language models (LLMs) have initiated a paradigm shift in transfer learning. In contrast to the classic pretraining-then-\ufb01netuning procedure, in order to use LLMs for downstream prediction tasks, one only needs to provide a few demonstrations, known as in-context examples, without adding more or updating existing model parameters. This in-context learning (ICL) capabilities of LLMs is intriguing, and it is not yet fully understood how pretrained LLMs acquire such capabilities. In this paper, we investigate the reason why a transformer-based language model can accomplish in-context learning after pre-training on a general language corpus by proposing one hypothesis that LLMs can simulate kernel regression algorithms when faced with in-context examples. More concretely, we \ufb01rst prove that Bayesian inference on in-context prompts can be asymptotically understood as kernel regression \u02c6 y = (cid:80) i y i K ( x,x i ) (cid:80) i K ( x,x i ) as the number of in-context demonstrations grows. Then, we empirically investigate the in-context behaviors of language models. We \ufb01nd that during ICL, the attentions and hidden features in LLMs match the behaviors of a kernel regression. Finally, our theory provides insights on multiple phenomena observed in ICL \ufb01eld: why retrieving demonstrative samples similar to test sample can help, why ICL performance is sensitive to the output formats, and why ICL accuracy bene\ufb01ts from selecting in-distribuion and representative samples. We will make our code available to the research community following publication."
}