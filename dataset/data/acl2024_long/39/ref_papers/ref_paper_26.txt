{
    "id": "c9dff8253b2e776abf363d0a4836abcaf64ee327",
    "title": "ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge",
    "abstract": ". Recent large language models (LLMs) in the general domain, such as ChatGPT, have shown remarkable success in following instructions and producing human-like responses. However, such language models have not been learned individually and carefully for the medical domain, resulting in poor diagnostic accuracy and inability to give correct recommendations for medical diagnosis, medications, etc. To address this issue, we collected more than 700 diseases and their corresponding symptoms, recommended medications, and required medical tests, and then generated 5K doctor-patient conversations. By \ufb01ne-tuning models of doctor-patient conversations, these models emerge with great potential to understand patients\u2019 needs, provide informed advice, and o\ufb00er valuable assistance in a variety of medical-related \ufb01elds. The integration of these advanced language models into healthcare can revolutionize the way healthcare professionals and patients communicate, ultimately improving the overall quality of care and patient outcomes. In addition, we will open all source code, datasets and model weights to advance the further development of dialogue models in the medical \ufb01eld. In addition, the training data, code, and weights of this project are available at: https:/"
}