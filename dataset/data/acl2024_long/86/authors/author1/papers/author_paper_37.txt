{
    "id": "e64bad304a6b2697d1fb01e9a0e6daa160ecdb17",
    "title": "Accelerating Pre-trained Language Models via Calibrated Cascade",
    "abstract": "Dynamic early exiting aims to accelerate pre-trained language models\u2019 (PLMs) inference by exiting in shallow layer without passing through the entire model. In this paper, we analyze the working mechanism of dynamic early exiting and \ufb01nd it cannot achieve a satisfying trade-off between inference speed and performance. On one hand, the PLMs\u2019 representations in shallow layers are not suf\ufb01-cient for accurate prediction. One the other hand, the internal off-ramps cannot provide reliable exiting decisions. To remedy this, we instead propose CascadeBERT, which dynamically selects a proper-sized, complete model in a cascading manner. To obtain more reliable model selection, we further devise a dif\ufb01culty-aware objective, encouraging the model output class probability to re\ufb02ect the real dif\ufb01culty of each instance. Extensive experimental re-sults demonstrate the superiority of our proposal over strong baseline models of PLMs\u2019 acceleration including both dynamic early exiting and knowledge distillation methods."
}