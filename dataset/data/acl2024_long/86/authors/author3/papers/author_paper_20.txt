{
    "id": "315899bf89296edf956cedc0ec4497bb74073a8b",
    "title": "Pre-trained multimodal end-to-end network for spoken language assessment incorporating prompts",
    "abstract": "Conventional systems for spoken language assessment rely on intermediate text features extracted from recognized transcripts by an automatic speech recognition (ASR) system, and/or additional handcrafted delivery features (e.g., pronunciation and fluency). It is challenging for less restricted tasks due to deteriorating performance of ASR and difficulty to design sufficient features. In this paper, we propose a multimodal end-to-end network with audio and text functioning as two modalities, avoiding utilizing intermediate features. We design a novel pre-training scheme to guide and tie the audio and text representations. Specifically, we utilize paired audio-transcript and premise-hypothesis data, where the former is commonly used for ASR training and the latter for natural language inference (NLI). The network is optimized by a multi-task learning (MTL) method combining a word matching task and an NLI task. The pre-trained network is then fine-tuned using a small number of paired audio-prompt and scoring data. Experimental results based on data from spoken English tests demonstrate the superior performance of the proposed model in Pearson correlation coefficient (PCC) and accuracy to the baselines."
}