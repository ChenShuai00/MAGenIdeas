{
    "id": "6ba1bf17723fe868f7693a3ffaadbd30f606e7ab",
    "title": "AVSBench: A Pixel-level Audio \u2212 Visual Segmentation Benchmark",
    "abstract": ". We propose to explore a new problem called audio-visual segmentation (AVS), whose goal is to output a pixel-level map of the object(s) that produce sound at the time of the image frame. To facilitate this research, we construct the first audio-visual segmentation benchmark (AVSBench), providing pixel-wise annotations for the sounding objects in audible videos. We propose two settings to be studied with AVSBench: 1) semi-supervised AVS with a single sound source and 2) fully-supervised AVS with multiple sound sources. We report the results of our baseline framework and six methods from the relevant tasks on our benchmark. Experiments demonstrate that AVSBench is promising for building a bridge between the audio and pixel-wise visual semantics."
}