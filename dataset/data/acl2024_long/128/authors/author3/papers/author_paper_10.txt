{
    "id": "79b3164aee108139cd1543a57f070881a470c8ee",
    "title": "LARGE-SCALE WORD REPRESENTATION FEATURES FOR IMPROVED SPOKEN LANGUAGE UNDERSTANDING",
    "abstract": "Recently there has been great interest in the application of word representation techniques to various natural language processing (NLP) scenarios. Word representation features from techniques such as Brown clustering or spectral clustering are generally computed from large corpora of unlabeled data in a completely unsupervised manner. These features can then be directly included as supplementary features to standard representations used for NLP processing tasks. In this paper, we apply these techniques to the tasks of domain classification and intent detection in a spoken language understanding (SLU) system. In experiments in a personal assistant domain, features derived from both Brown clustering and spectral clustering techniques improved the performance of all models in our experiments and the combination of both techniques yielded additional improvements."
}