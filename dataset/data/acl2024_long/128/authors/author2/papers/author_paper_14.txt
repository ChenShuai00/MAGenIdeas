{
    "id": "5eb38b667ef6e594670ead4d21f41922e9df80c1",
    "title": "CiteSum: Citation Text-guided Scientific Extreme Summarization and Low-resource Domain Adaptation",
    "abstract": "Scienti\ufb01c extreme summarization (TLDR) aims to form ultra-short summaries of scienti\ufb01c papers. Previous efforts on curating scienti\ufb01c TLDR datasets failed to scale up due to the heavy human annotation and domain ex-pertise required. In this paper, we propose a simple yet effective approach to automatically extracting TLDR summaries for scienti\ufb01c papers from their citation texts. Based on the proposed approach, we create a new benchmark CiteSum without human annotation, which is around 30 times larger than the previous human-curated dataset SciTLDR. We conduct a comprehensive analysis of CiteSum, exam-ining its data characteristics and establishing strong baselines. We further demonstrate the usefulness of CiteSum by adapting models pretrained on CiteSum (named C I T E S) to new tasks and domains with limited supervision. For scienti\ufb01c extreme summarization, C I T E S outperforms most fully-supervised methods on SciTLDR without any \ufb01ne-tuning and ob-tains state-of-the-art results with only 128 examples. For news extreme summarization, C I T E S achieves signi\ufb01cant gains on XSum over its base model (not pre-trained on Cite-Sum), e.g. , +7.2 ROUGE-1 zero-shot performance and state-of-the-art few-shot performance. For news headline generation, C I T E S performs the best among unsupervised and zero-shot methods on Gigaword. 1 Paper Abstract : We study the problem of transferring a sample in one domain to an analog sample in another domain . Given two related domains, S and T , we would like to learn a generative function G that maps an input sample from S to the domain T , such that the output of a given function f , which accepts inputs in either domains, would remain unchanged. Other than the function f , the training data is unsupervised and consist of a set of samples from each domain. The Domain Transfer Network (DTN) we present employs a compound loss function that includes a multiclass GAN loss, an f -constancy component, and a regularizing component that encourages G to map samples from T to themselves. We apply our method to visual domains including digits and face images and demonstrate its ability to generate convincing novel images of previously unseen entities, while preserving their identity. Congested states in empirical observations and microscopic simulations Paper Abstract : We present data from several German freeways showing different kinds of congested traf\ufb01c forming near road inhomogeneities, speci\ufb01cally lane closings, intersections, or uphill gradients. The states are localized or extended, homogeneous or oscillating. Combined states are observed as well, like the coexistence of moving localized clusters and clusters pinned at road inhomogeneities, or regions of oscillating congested traf\ufb01c upstream of nearly homogeneous congested traf\ufb01c. The experimental \ufb01ndings are consistent with a recently proposed theoretical phase diagram for traf\ufb01c near on-ramps [D. Helbing, A. Hennecke, and M. Treiber, Phys. Rev. Lett. 82, 4360 (1999)]. We simulate these situations with a novel continuous microscopic single-lane model, the \"intelligent driver model\" (IDM), using the empirical boundary conditions. All observations, including the coexistence of states, are qualitatively reproduced by describing inhomogeneities with local variations of one model parameter. We show that the results of the microscopic model can be understood by formulating the theoretical phase diagram for bottlenecks in a more general way. In particular, a local drop of the road capacity induced by parameter variations has practically the same effect as an on-ramp. In a \ufb01rst approach, we use the well-known \"intelligent driver model\" (IDM) REF to show that the method works. Paper Abstract : Meta-learning for few-shot learning entails acquiring a prior over previous tasks and experiences, such that new tasks be learned from small amounts of data. However, a critical challenge in few-shot learning is task ambiguity: even when a powerful prior can be meta-learned from a large number of prior tasks, a small dataset for a new task can simply be too ambiguous to acquire a single model (e.g., a classi\ufb01er) for that task that is accurate. In this paper, we propose a probabilistic meta-learning algorithm that can sample models for a new task from a model distribution. Our approach extends model-agnostic meta-learning, which adapts to new tasks via gradient descent, to incorporate a parameter distribution that is trained via a variational lower bound. At meta-test time, our algorithm adapts via a simple procedure that injects noise into gradient descent, and at meta-training time, the model is trained such that this stochastic adaptation procedure produces samples from the approximate model posterior. Our experimental results show that our method can sample plausible classi\ufb01ers and regressors in ambiguous few-shot learning problems. Method Paper Abstract : Light \ufb01eld cameras can capture both spatial and angular information of light rays, enabling 3D reconstruction by a single exposure. The geometry of 3D reconstruction is affected by intrinsic parameters of a light \ufb01eld camera signi\ufb01cantly. In the paper, we propose a multi-projection-center (MPC) model with 6 intrinsic parameters to characterize light \ufb01eld cameras based on traditional twoparallel-plane (TPP) representation. The MPC model can generally parameterize light \ufb01eld in different imaging formations, including conventional and focused light \ufb01eld cameras. By the constraints of 4D ray and 3D geometry, a 3D projective transformation is deduced to describe the relationship between geometric structure and the MPC coordinates. Based on the MPC model and projective transformation, we propose a calibration algorithm to verify our light \ufb01eld camera model. Our calibration method includes a close-form solution and a non-linear optimization by minimizing re-projection errors. Experimental results on both simulated and real scene data have veri\ufb01ed the performance of our algorithm. Citation Text : Zhang et al REF proposed a multi-projection-center (MPC) model with six intrinsic parameters to characterize both conventional and focused LF cameras. Abstract-Cloud computing, evolved computing, virtualisation"
}