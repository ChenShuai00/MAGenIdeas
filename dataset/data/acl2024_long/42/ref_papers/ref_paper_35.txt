{
    "id": "d7b10939d09776b9b10b4555f20577d3dc6697fc",
    "title": "Why Don\u2019t You Do It Right? Analysing Annotators\u2019 Disagreement in Subjective Tasks",
    "abstract": "Annotators\u2019 disagreement in linguistic data has been recently the focus of multiple initiatives aimed at raising awareness on issues related to \u2018majority voting\u2019 when aggregating diverging annotations. Disagreement can indeed reflect different aspects of linguistic annotation, from annotators\u2019 subjectivity to sloppiness or lack of enough context to interpret a text. In this work we first propose a taxonomy of possible reasons leading to annotators\u2019 disagreement in subjective tasks. Then, we manually label part of a Twitter dataset for offensive language detection in English following this taxonomy, identifying how the different categories are distributed. Finally we run a set of experiments aimed at assessing the impact of the different types of disagreement on classification performance. In particular, we investigate how accurately tweets belonging to different categories of disagreement can be classified as offensive or not, and how injecting data with different types of disagreement in the training set affects performance. We also perform offensive language detection as a multi-task framework, using disagreement classification as an auxiliary task."
}