{
    "id": "ef288527a39419065a05f1b0e86bd69140df9387",
    "title": "Identifying Factual Inconsistency in Summaries: Large Language Model is Ready to Help",
    "abstract": "Factual inconsistency poses a significant hurdle 001 for the commercial deployment of abstractive 002 summarizers. Under this new era of Large Lan-003 guage Model (LLM), this work focuses around 004 two important questions: what is the best way 005 to leverage LLM for factual inconsistency de-006 tection, and how could we distill a smaller 007 LLM with both high efficiency and efficacy? 008 Three zero-shot paradigms are firstly proposed 009 and evaluated across five diverse datasets: di-010 rect inference on the entire summary or each 011 summary window; entity verification through 012 question generation and answering. Our ex-013 periments suggest that LLM itself is capable 014 to resolve this task directly under the correct 015 paradigm design, which surpasses the baselines 016 by up to 4.7% on average. To further promote 017 efficiency for practical use, we then propose 018 training strategies to distill smaller open-source 019 LLM that learns to score the entire summary 020 at once with high accuracy, which outperforms 021 the zero-shot approaches by much larger LLM, 022 serving as an effective ready-to-use scorer. 023"
}