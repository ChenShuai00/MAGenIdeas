{
    "id": "42716a402c85f74c5f907316b23d87bc0dbd0b62",
    "title": "Few-Shot Causal Distillation",
    "abstract": "Model distillation is a technique that replicates the performance of a large model (teacher) in a small model (student) by adding an objective to match the output of the teacher when training the student. It has been shown that adding a third objective that encourages the student to match causal dynamics of the teacher by using a distillation interchange intervention training objective (DIITO) can further increase the performance of the student. DIITO swaps the internal representations of both the student and teacher models with a counter-factual representation and attempts to match the change in output between the student and teacher. However, the best way to perform DIITO has been under explored in the small-data regime. In this paper we explore two different parts of DIITO: the mapping of the teacher layers to the student layers, and strategies to generate effective counter-factual representations. We explore scheduling the alignment of the student and teacher models top-down and bottom-up. Additionally we explore using synonyms, antonyms, meronyms, holonyms, and random noise as counterfactual inputs. Finally, we explore doing away with the counter-factual examples entirely, instead directly modifying the intervention internal representations. When testing on portions of the GLUE benchmark suite, the main findings of this paper are: random alignment of all layers works best, the counterfactual example should use the same context as the base network, and the counterfactual example can be eliminated entirely which saves time and memory costs."
}