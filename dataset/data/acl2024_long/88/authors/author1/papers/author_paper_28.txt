{
    "id": "05840877433670c00566af4ed6946080685b0075",
    "title": "Formality Favored: Unraveling the Learning Preferences of Large Language Models on Data with Conflicting Knowledge",
    "abstract": "Having been trained on massive pretraining 001 data, large language models have shown excel-002 lent performance on many knowledge-intensive 003 tasks. However, pretraining data tends to con-004 tain misleading and even conflicting informa-005 tion, and it is intriguing to understand how 006 LLMs handle these noisy data during train-007 ing. In this study, we systematically analyze 008 LLMs\u2019 learning preferences for data with con-009 flicting knowledge. We find that pretrained 010 LLMs establish learning preferences similar to 011 humans, i.e., preferences towards formal texts 012 and texts with fewer spelling errors, resulting 013 in faster learning and more favorable treatment 014 of knowledge in data with such features when 015 facing conflicts. This finding is generalizable 016 across models and languages and is more ev-017 ident in larger models. An in-depth analysis 018 reveals that LLMs tend to trust data with fea-019 tures that signify consistency with the majority 020 of data, and it is possible to instill new prefer-021 ences and erase old ones by manipulating the 022 degree of consistency with the majority data. 023"
}