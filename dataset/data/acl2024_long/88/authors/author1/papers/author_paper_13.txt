{
    "id": "64d1df0c20871b509c2b4f4688908d6c6ae64cd6",
    "title": "An Active Learning Interface for Bootstrapping Robot \u2019 s Generalization Abilities in Learning from Demonstration",
    "abstract": "We consider combining thenon-linear dynamicalsystems\u2019 motion representation with theactive learning paradigm as an approach to enhance motion learning and generalization abilities in robots. We suggest to design the learning process so that a robot can gradually expandits generalizationcapacities by requesting new demonstrations that extend a region of the applicability of the learned dynamics of a motion; see Figure 1. To allow for such a learning process, we extend our previous work on learning motion dynamics [ 1] with the iterative algorithm for estimating the region of applicability and the algorithm for estimating the consistency of new demonstrations with respect to the learned model. In the previous work of ours [ 1], we propose an algorithm for estimating thenon-linear dynamicsof motion in thestate-space . Our system encapsulates local correlation patterns between the motion\u2019s variables and provides the actual temporal robustness. The dynamics learned this way has a local character due to its nonlinear form (local stability) and the limited generalization power of the statistical inference (farther from the demonstrated data the reliability of the inferences degrades.) 1 To be efficiently applied in practice, the learned dynamical model requires an estimate of its region of applicability, i.e. the estimate of the boundaries of the invariant sub-space where all trajectories converge to the target and where the confidence of the statistical inference allows generating the relevant trajectories. The size of this region determines the generalization abilities of the learned representation. Here we discuss how this region can be systematically expanded through additional demonstrations obtained with support of the suggested active learning interface. Our approach to motion learning combines several demonstrations and, therefore, introduces a view on motion learning which is essentially different than the one, adopted in the other approaches to learning motion dynamics, where the authors consider learning from a single demonstration [ 2]. It has been acknowledged that combining several demonstrations is advantageous for motion learning [3]. Indeed, in our case, this allows a robot to generalize its knowledge from sub-optimal demonstrations and accurately reproduce the task\u2019s trajectories, starting from any point in the region of applicability. However, while introducing the advantages in terms of improved generalization, learning from multiple demonstrations requires more efforts from a human teacher. In addition to repeating a motion several times, he/she should control the variability and consistency of the demonstrations. As an attempt to support the human during the teaching process, we present a generic interface for robot active learning that allows the robot learner to become"
}