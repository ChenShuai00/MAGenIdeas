{
    "id": "d610e066e5c3cc7eda13313554e25a340ce18f71",
    "title": "Hopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries",
    "abstract": "Large language models (LLMs) can solve complex multi-step problems, but little is known about how these computations are implemented internally. Motivated by this, we study how LLMs answer multi-hop queries such as \u201cThe spouse of the performer of Imagine is\u201d. These queries require two information extraction steps: a latent one for resolving the first hop (\u201cthe performer of Imagine\u201d) into the bridge entity (John Lennon), and another for resolving the second hop (\u201cthe spouse of John Lennon\u201d) into the target entity (Yoko Ono). Understanding how the latent step is computed internally is key to understanding the overall computation. By carefully analyzing the internal computations of transformer-based LLMs, we discover that the bridge entity is resolved in the early layers of the model. Then, only after this resolution, the two-hop query is solved in the later layers. Because the second hop commences in later layers, there could be cases where these layers no longer encode the necessary knowledge for correctly predicting the answer. Motivated by this, we propose a novel \u201cback-patching\u201d analysis method whereby a hidden representation from a later layer is patched back to an earlier layer. We find that in up to 66% of previously incorrect cases there exists a back-patch that results in the correct generation of the answer, showing that the later layers indeed sometimes lack the needed functionality. Overall our methods and findings open further opportunities for understanding and improving latent reasoning in transformer-based LLMs."
}