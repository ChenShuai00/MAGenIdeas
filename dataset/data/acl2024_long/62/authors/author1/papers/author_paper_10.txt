{
    "id": "8c26bb5bf958202707b2ae1823fd2b4136dfd224",
    "title": "P ERFECT : Prompt-free and Efficient Language Model Fine-Tuning",
    "abstract": "Current methods for few-shot fine-tuning of 001 pretrained masked language model (PLM) require 002 carefully engineered prompts and verbalizers 003 for each new task, to convert examples into a 004 cloze-format that the PLM can score. In this work, 005 we propose P ERFECT , a simple and efficient 006 method for few-shot fine-tuning of PLMs without 007 relying on any such handcrafting , which is highly 008 effective given as few as 32 data points. P ERFECT 009 makes two key design choices: First, we show 010 that manually engineered task prompts can be 011 replaced with task-specific adapters that enable 012 sample-efficient fine-tuning and reduce memory 013 and storage costs by roughly factors of 5 and 100, 014 respectively. Second, instead of using handcrafted 015 verbalizers, we learn a new multi-token label em-016 bedding during fine-tuning which are not tied to 017 the model vocabulary and which allow us to avoid 018 complex auto-regressive decoding. These embed-019 dings are not only learnable from limited data but 020 also enable nearly 100x faster training and infer-021 ence. Experiments on a wide range of few shot 022 NLP tasks demonstrate that P ERFECT , while be-023 ing simple and efficient, also outperforms existing 024 state-of-the-art few-shot learning methods. 1 025"
}