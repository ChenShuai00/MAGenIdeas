{
    "id": "9a0ffb6156763be319a1ea39c9fac4080bc61182",
    "title": "Reinforced Clarification Question Generation with Defeasibility Rewards for Disambiguating Social and Moral Situations",
    "abstract": "Context is vital for commonsense moral reasoning. \u201cLying to a friend\" is wrong if it is meant to deceive them, but may be morally okay if it is intended to protect them. Such nuanced but salient contextual information can potentially \ufb02ip the moral judgment of an action. Thus, we present C LARIFY D ELPHI , an interactive system that elicits missing contexts of a moral situation by generating clari\ufb01cation questions such as \u201cWhy did you lie to your friend?\". Our approach is inspired by the observation that questions whose potential answers lead to diverging moral judgments are the most informative. We learn to generate questions using Reinforcement Learning, by maximizing the divergence between moral judgements of hypothetical answers to a question. Human evaluation shows that our system generates more relevant , informative and defeasible questions compared to other question generation baselines. C LARIFY D ELPHI assists informed moral reasoning processes by seeking additional morally consequential context to disambiguate social and moral situations."
}