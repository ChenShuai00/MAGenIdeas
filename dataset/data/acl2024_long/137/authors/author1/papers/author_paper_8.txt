{
    "id": "36ec62d9631e60a4471adbf5d38b190b5434a9b4",
    "title": "S 2 ynRE: Two-stage Self-training with Synthetic data for Low-resource Relation Extraction",
    "abstract": "Current relation extraction methods suffer from 001 the inadequacy of large-scale annotated data. 002 While distant supervision alleviates the prob-003 lem of data quantities, there still exists domain 004 disparity in data qualities due to its reliance 005 on domain-restrained knowledge bases. In this 006 work, we propose S 2 ynRE, a framework of two-007 stage Self-training with Synthetic data for Rela-008 tion Extraction. We \ufb01rst leverage the capability 009 of large language models to adapt to the tar-010 get domain and automatically synthesize large 011 quantities of coherent, realistic training data. 012 We then propose an accompanied two-stage 013 self-training algorithm that iteratively and al-014 ternately learns from synthetic and golden data 015 together. We conduct comprehensive experi-016 ments and detailed ablations on popular rela-017 tion extraction datasets to demonstrate the ef-018 fectiveness of the proposed framework. Specif-019 ically under low resource settings, S 2 ynRE 020 brings up to 17.18% absolute improvements 021 and 12.63% on average across all datasets. 022"
}