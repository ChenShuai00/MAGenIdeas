{
    "id": "87ae705a3ac98bb485e55a93b94855d66a220f14",
    "title": "Multi-Task Learning For Parsing The Alexa Meaning Representation Language",
    "abstract": "\n \n The Alexa Meaning Representation Language (AMRL) is a compositional graph-based semantic representation that includes fine-grained types, properties, actions, and roles and can represent a wide variety of spoken language. \u00a0AMRL increases the ability of virtual assistants to represent more complex requests, including logical and conditional statements as well as ones with nested clauses. Due to this representational capacity, the acquisition of large scale data resources is challenging, which limits the accuracy of\u00a0resulting models. This paper has two primary contributions. First, we develop a\u00a0linearization of\u00a0AMRL graphs along with a deep multi-task model that predicts\u00a0fine-grained types, properties, and intents. Second, we show how to jointly train a model that predicts an existing representation for spoken language understanding (SLU) along with the linearized AMRL parse. The resulting model, which leverages learned embeddings from both tasks, is able to predict the AMRL\u00a0representation\u00a0more accurately than other approaches, decreasing the error\u00a0rates in the full\u00a0parse by 3.56% absolute and reducing the amount of natively\u00a0annotated data\u00a0needed to train accurate parsing models.\n \n"
}