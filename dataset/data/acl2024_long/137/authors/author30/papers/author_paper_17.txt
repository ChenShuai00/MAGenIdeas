{
    "id": "c91409a72b05d04cfc85d6a3277170272494f92e",
    "title": "Evaluating Compositionality in Neural Models Using Arithmetic Expressions",
    "abstract": "We introduce CobA, a dataset designed to eval-001 uate the compositional properties of neural 002 models. The dataset consists of simple arith-003 metic expressions combining natural integers 004 with addition and multiplication operators. For 005 example, (5 + 4) \u00d7 2 . We distinguish four 006 aspects of compositionality: localism, substi-007 tutivity, productivity, and systematicity. We 008 generate partitions of the dataset with specific 009 in-domain and generalization sets, designed 010 to evaluate the model\u2019s ability for each com-011 positional aspect. By carefully selecting ex-012 pressions from the in-domain and generaliza-013 tion sets, we introduce controlled differences 014 between the two sets. We show that models 015 achieve competitive performance on a random 016 partition, for which there is no controlled dif-017 ference. Yet, for partitions requiring composi-018 tional extrapolation, performances drastically 019 decrease for most encoder architectures. We 020 observe distinctions among architectures, in 021 particular fixed-length context transformers, se-022 quential or tree-structured LSTM. 023"
}