{
    "id": "68e0bf8526bb784feaeca0de7de2980c1e77d94b",
    "title": "CSL: A Large-scale Chinese Scienti\ufb01c Literature Dataset for Cross-task Evaluation",
    "abstract": "Scienti\ufb01c literature serves as a high-quality 001 corpus, which could provide natural annotated 002 data for many natural language processing 003 (NLP) research. In this work, we introduce 004 a C hinese S cienti\ufb01c L iterature dataset \u2013 CSL, 005 which contains the titles, abstracts, keywords 006 and academic \ufb01elds of 400,000 papers. The 007 rich semantic information in these scienti\ufb01c lit-008 erature creates extensive NLP tasks and pro-009 vides a natural cross-task scenario. Based on 010 this, we present a cross-task few-shot bench-011 mark. To evaluate the cross-task transferabil-012 ity of the model, we design scenarios with 013 different aspects and dif\ufb01culties. Compared 014 with previous cross-task benchmarks, these 015 tasks are constructed from homogeneous cor-016 pus, allowing researchers to investigate the re-017 lationships between tasks, without being dis-018 turbed by heterogeneous data sources, annota-019 tion, and other factors. We analyze the behav-020 ior of existing text-to-text models on the pro-021 posed benchmark, and reveal the challenges 022 for cross-task generalization, which provides 023 a valuable reference for future research. Code 024 and data are publicly available at GitHub 1 . 025"
}