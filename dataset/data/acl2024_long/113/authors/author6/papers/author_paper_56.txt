{
    "id": "075ef06420ca5c9f1acabf6adc0b63918d518820",
    "title": "Overleaf Example",
    "abstract": "Recent methods for embodied instruction following are typically trained end-toend using imitation learning. This requires the use of expert trajectories and lowlevel language instructions. Such approaches assume learned hidden states will simultaneously integrate semantics from the language and vision to perform state tracking, spatial memory, exploration, and long-term planning. In contrast, we propose a modular method with structured representations that (1) builds a semantic map of the scene, and (2) performs exploration with a semantic search policy, to achieve the natural language goal. Our modular method achieves SOTA performance (24.46%) with a substantial (8.17 % absolute) gap from previous work while using less data by eschewing both expert trajectories and low-level instructions. Leveraging low-level language, however, can further increase our performance (26.49%).1 Our findings suggest that an explicit spatial memory and a semantic search policy can provide a stronger and more general representation for state-tracking and guidance, even in the absence of expert trajectories or lowlevel instructions.2"
}