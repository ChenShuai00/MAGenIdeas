{
    "id": "5d47143c13591def061e203bf6dd6d97fd110631",
    "title": "KRIT: Knowledge-Reasoning Intelligence in vision-language Transformer",
    "abstract": "Transformer-based pretraining techniques have achieved impressive performance on learning cross-model representations for various multi-modality tasks. However, most off-the-shelf models do not take advantage of commonsense knowledge and logical reasoning that are crucial to many real-world tasks. To this end, we introduce a new variant of the Transformer model for representation learning, K nowledge R easoning I ntelligence in Vision-Language T ransformer (KRIT). It utilizes a reasoning module and the commonsense knowledge embeddings extracted from text and detected image object tags to perform knowledge-grounded representation learning to improve model generalization and interpretability. KRIT is pretrained on a large image-text corpus and automatically extracted knowledge embeddings, and then finetuned on several downstream vision-language tasks. Experiments show that KRIT not only achieve the significant result on the OK-VQA task, but also for the first time, to the best of our knowledge, make the transformer model interpretable by illustrating its reasoning via a set of rules."
}