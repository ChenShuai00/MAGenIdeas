{
    "id": "4e37589fb896d1578ba4282f40c20708079ae8e5",
    "title": "Commonsense Reasoning for Conversational AI: A Survey of Recent Datasets and Benchmarks",
    "abstract": "Large, transformer-based pretrained language 001 models like BERT, GPT, and T5 have demon-002 strated a deep understanding of contextual se-003 mantics and language syntax, enabling near hu-004 man levels of success on a variety of natural lan-005 guage processing tasks. However, these mod-006 els still struggle with tasks that involve higher 007 levels of reasoning - including commonsense 008 reasoning that humans find trivial. The deficien-009 cies of pretrained models are especially preva-010 lent in human-to-human (H2H) conversations, 011 where commonsense knowledge between hu-012 mans is assumed. This paper presents a survey 013 of recent conversational AI research on H2H 014 dialogues with a focus on commonsense rea-015 soning. We survey the popular datasets in this 016 area, review commonsense knowledge sources, 017 and categorize research according to the lan-018 guage tasks used for training and evaluation. 019 We conduct a preliminary comparison of lead-020 ing methods on the task of abstractive dialogue 021 summarization. The analysis motivates direc-022 tions for future research in commonsense rea-023 soning for conversational AI. 024"
}