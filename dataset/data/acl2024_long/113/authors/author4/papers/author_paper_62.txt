{
    "id": "40c3327a6ddb0603b6892344509c7f428ab43d81",
    "title": "Documenting the English Colossal Clean Crawled Corpus",
    "abstract": "As language models are trained on ever more text, researchers are turning to some of the largest corpora available. Unlike most other types of datasets in NLP, large unlabeled text corpora are often presented with minimal documentation, and best practices for documenting them have not been established. In this work we provide the \ufb01rst documentation for the Colossal Clean Crawled Corpus (C4; Raf-fel et al., 2020), a dataset created by applying a set of \ufb01lters to a single snapshot of Common Crawl. We begin with a high-level summary of the data, including distributions of where the text came from and when it was written. We then give more detailed analysis on salient parts of this data, including the most frequent sources of text (e.g. patents.google.com , which contains a signi\ufb01cant percentage of machine translated and/or OCR\u2019d text), the effect that the \ufb01lters had on the data (they disproportionately remove text in AAE), and evidence that some other benchmark NLP dataset examples are contained in the text. We release a web interface to an interactive, indexed copy of this dataset, encouraging the community to continuously explore and report additional \ufb01ndings."
}