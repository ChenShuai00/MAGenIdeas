{
    "id": "c386c0394f0a5a27a8618d980473161083ab4d46",
    "title": "LawngNLI: a multigranular, long-premise NLI benchmark for evaluating models\u2019 in-domain generalization from short to long contexts",
    "abstract": "Natural language inference has trended with 001 NLP toward studying reasoning over long con-002 texts, with several datasets moving beyond 003 the sentence level. However, short-sequence 004 models typically perform best despite their 005 sequence limits. Confounded by domain 006 shifts between datasets, it has remained un-007 clear whether long premises are truly needed 008 at \ufb01ne-tuning time to learn long-premise NLI. 009 We construct LawngNLI, 1 with premises that 010 skew much longer than in existing NLI bench-011 marks and are multigranular: all contain a 012 short version. LawngNLI is constructed from 013 U.S. legal opinions, with automatic labels with 014 high human-validated accuracy. Evaluating 015 on its long-premise NLI, we show top perfor-016 mance is achieved only with \ufb01ne-tuning us-017 ing these long premises. Models only \ufb01ne-018 tuned on existing datasets and even our short 019 premises (which derive from judge-selected 020 relevant Entail excerpts in source documents) 021 thus controlling for domain underperform con-022 siderably. Top performance is by short-023 sequence models prepended with a standard 024 retrieval method \ufb01ltering across each premise, 025 but they underperform absent \ufb01ne-tuning us-026 ing long premises as inputs. LawngNLI also 027 holds relevance for the legal community, as 028 NLI is a principal cognitive task in develop-029 ing cases and advice. Models performing well 030 could double as retrieval or implication scor-031 ing systems for legal cases. 032"
}