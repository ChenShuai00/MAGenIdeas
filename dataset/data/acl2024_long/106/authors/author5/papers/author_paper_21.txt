{
    "id": "8a0e12ab7f324093f7f4a8d1b42a1d2f7a4e459d",
    "title": "Measuring Factual Consistency of Abstractive Summaries",
    "abstract": "Recent abstractive summarization systems fail 001 to generate factual consistent \u2013 faithful \u2013 sum-002 maries, which heavily limits their practical ap-003 plication. Commonly, these models tend to 004 mix concepts from the source or hallucinate 005 new content, completely ignoring the source. 006 Addressing the faithfulness problem is perhaps 007 the most critical challenge for current abstrac-008 tive summarization systems. First automatic 009 faithfulness metrics were proposed, but we ar-010 gue that existing methods do not yet utilize 011 all \"machinery\" that this \ufb01eld has to offer 012 and introduce new approaches to assess fac-013 tual correctness. We evaluate existing and our 014 proposed methods by correlating them with 015 human judgements and \ufb01nd that BERTScore 016 works well. Next, we conduct a data analy-017 sis, which reveals common problems, ways to 018 further improve the metrics and indicates that 019 combining multiple metrics is promising. Fi-020 nally, we exploit faithfulness metrics in pre-021 and post-processing steps to decrease factual 022 errors made by state-of-the-art summarization 023 systems. We \ufb01nd that simple techniques like 024 \ufb01ltering training data and re-ranking generated 025 summaries can increase the faithfulness by a 026 substantial margin. 027"
}