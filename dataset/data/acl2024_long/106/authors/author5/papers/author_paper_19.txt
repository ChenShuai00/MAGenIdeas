{
    "id": "5bdf42b74e9fefb6491ad4d950045c2a887b1373",
    "title": "TASA: Twin Answer Sentences Attack for Adversarial Context Generation in Question Answering",
    "abstract": "We present T win A nswer S entences A ttack 001 (TASA), a novel question answering (QA) ad-002 versarial attack method that produces \ufb02uent 003 and grammatical adversarial contexts while 004 maintaining its gold answers. Despite phenom-005 enal progresses on general adversarial attacks, 006 few works have investigated the vulnerability 007 and adversarial attack speci\ufb01cally for QA. In 008 this work, we \ufb01rst investigate the biases in the 009 existing models and discover that they heav-010 ily rely on keyword matching and ignore the 011 relevant entities from the question. TASA ex-012 plores the two biases above and attacks the 013 target model in two folds: (1) lowering the 014 model\u2019s con\ufb01dence on the gold answer with a 015 perturbed answer sentence ; (2) misguiding the 016 model towards a wrong answer with a distract-017 ing answer sentence . Equipped with designed 018 beam search and \ufb01ltering methods, TASA is 019 able to attack the target model ef\ufb01ciently while 020 sustaining the quality of contexts. Extensive 021 experiments on four QA datasets and human 022 evaluations demonstrate that TASA generates 023 substantial-high-quality attacks than existing 024 textual adversarial attack methods. 025"
}