{
    "id": "072d90d73f307b5fe04f54df59dd4110621565d1",
    "title": "Question-Led Semantic Structure Enhanced Attentions for VQA",
    "abstract": "The exploit of the semantic structure in the 001 visual question answering (VQA) task is a 002 trending topic where researchers are interested 003 in leveraging internal semantics and bringing 004 in external knowledge to tackle more com-005 plex questions. The prevailing approaches 006 either encode the external knowledge sepa-007 rately from the local context, which magnif-008 icently increases the complexity of the ensem-009 ble system, or use graph neural networks to 010 model the semantic structure in the context, 011 which suffers from the limited reasoning ca-012 pability due to the relatively shallow network. 013 In this work, we propose a question-led struc-014 ture extraction scheme using external knowl-015 edge and explore multiple training methods, in-016 cluding direct attention supervision, SGHMC-017 EM Bayesian multitask learning, and masking 018 strategies, to aggregate the structural knowl-019 edge into deep models without changing the ar-020 chitectures. We conduct extensive experiments 021 on two domain-specific but challenging sub-022 tasks of VrR-VG dataset and demonstrate that 023 our proposed methods achieve significant im-024 provements over strong baselines, showing the 025 promising potentials of applicability. 026"
}