{
    "id": "2b8c6c2ae778184f41db3467ed2cde5342aae676",
    "title": "RiddleSense: Answering Riddle Questions as Commonsense Reasoning",
    "abstract": "A riddle is a mystifying, puzzling question about everyday concepts. For example, the riddle \u201c I have \ufb01ve \ufb01ngers but I am not alive. What am I? \u201d asks about the concept \u201c a glove .\u201d Solving riddles is a challenging cognitive process for humans, in that it requires complex commonsense reasoning abilities and an understanding of \ufb01gurative language. However, there are currently no commonsense reasoning datasets that test these abilities. We propose R IDDLE S ENSE 1 , a novel multiple-choice question answering challenge for benchmarking higher-order commonsense reasoning models, which is the \ufb01rst large dataset for riddle-style commonsense question answering, where the distractors are crowd-sourced from human annotators. We systematically evaluate a wide range of reasoning models over it, and point out that there is a large gap between the best-supervised model and human performance \u2014 pointing to interesting future research for higher-order commonsense reasoning and computational creativity."
}