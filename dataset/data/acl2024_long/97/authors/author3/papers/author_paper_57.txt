{
    "id": "e7636f63deec9520b13fec6fd1e9b871eb9fc44c",
    "title": "L G ] 2 6 M ay 2 01 9 Enhancing ML Robustness Using Physical-World Constraints",
    "abstract": "Recent advances in Machine Learning (ML) have demonstrated that neural networks can exceed human performance in many tasks, including vision. While generalizing well over natural inputs, neural networks are vulnerable to adversarial inputs. An adversarially perturbed input is \u201csimilar\u201d to the original input, but misclassified by the model. Existing defenses against adversarial inputs have largely been detached from the real world. They focus on lp-norm bounded adversaries that perturb ML inputs in the digital space. In the real world, however, attackers can generate adversarial perturbations that have a large lp-norm in the digital space. These perturbations, while misinterpreted by ML models, can be indiscernible to humans. These defenses also come at a cost to accuracy, making their applicability questionable in the real world. To defend models against such a powerful adversary, we can leverage one constraint on its power: the perturbation should not change the human\u2019s perception of the physical information; the physical world places some constraints on the space of possible attacks. Two questions follow: how to extract and model these constraints? and how to design a classification paradigm that leverages these constraints to improve robustness accuracy trade-off? We observe that an ML model is typically a part of a larger system with access to different input modalities. Utilizing these modalities, we introduce invariants that limit the attacker\u2019s action space. We design a hierarchical classification paradigm that enforces these invariants at inference time. We find that applying invariants to the classification task makes robustness and accuracy feasible together. As a case study, we implement and evaluate our proposal in the context of the real-world application of road sign classification because of its applicability to autonomous driving. With access to different input modalities, such as LiDAR, camera, and location we show how to extract invariants and develop a hierarchical classifier. Our results on the KITTI University of Wisconsin-Madison Google"
}