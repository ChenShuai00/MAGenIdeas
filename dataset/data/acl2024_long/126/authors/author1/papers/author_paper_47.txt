{
    "id": "025821369f49fbdb4de28b39800798b5de2d9ae8",
    "title": "Supervised Contrastive Meta-learning for Few-Shot Classification",
    "abstract": "Many works have demonstrated that it is important to learn good representations for few-shot classification (FSC) problem. Contrastive learning produces encouraging results in unsupervised representation learning which aims at providing a good pre-trained feature extractor for the downstream tasks. It is a feasible way to utilize contrastive learning methods to provide a good pre-trained feature extractor for few-shot classification tasks. However, standard contrastive learning approaches do not achieve adequate results. On the one hand, contrastive learning can only perform instance-level learning due to the inability to use label information. On the other hand, existing contrastive learning lacks generalization ability while the class of downstream tasks is unseen. Meta-learning provides an approach to increase the model's capacity for generalization. We provide a supervised contrastive meta-learning model (SCML) which takes advantage of the capacity of meta-learning to swiftly adjust to novel tasks to improving the generalization ability of contrastive learning while utilizing the label information of the data for learning better representations. The result of experiments on different benchmarks shows the superior performance of the supervised contrastive meta-learning in terms of generalization ability for novel tasks. Furthermore, compared with the typical methods of meta-learning, our model SCML demonstrates appealing performance on MiniImagenet and CIFAR-FS."
}