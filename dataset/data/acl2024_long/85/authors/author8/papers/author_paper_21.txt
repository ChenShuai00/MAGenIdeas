{
    "id": "8f2f6d90de822888ec4e283788bc09917018e9d6",
    "title": "ImageNetVC: Zero-Shot Visual Commonsense Evaluation on 1000 ImageNet Categories",
    "abstract": "Recently, Pretrained Language Models (PLMs) have been serving as general-purpose interfaces, posing a significant demand for comprehensive visual knowledge. However, it remains unclear how well current PLMs and their visually augmented counterparts (VaLMs) can master visual commonsense knowledge. To investigate this, we propose I MAGE N ET VC, a fine-grained, human-annotated dataset specifically designed for zero-shot visual common-sense evaluation across 1,000 ImageNet categories. Utilizing I MAGE N ET VC, we delve into the fundamental visual commonsense knowledge of both unimodal PLMs and VaLMs, un-covering the scaling law and the influence of the backbone model on VaLMs. Furthermore, we investigate the factors affecting the visual commonsense knowledge of large-scale models, providing insights into the development of language models enriched with visual commonsense knowledge. Our code and dataset are available at https://github.com/hemingkx/ ImageNetVC ."
}