{
    "id": "62e4f96797c8c1d7e4fcc2bcb2d4a3b6039cf59b",
    "title": "HITS: High-coverage LLM-based Unit Test Generation via Method Slicing",
    "abstract": "Large language models (LLMs) have behaved well in generating unit tests for Java projects. However, the performance for covering the complex focal methods within the projects is poor. Complex methods comprise many conditions and loops, requiring the test cases to be various enough to cover all lines and branches. However, existing test generation methods with LLMs provide the whole method-to-test to the LLM without assistance on input analysis. The LLM has difficulty inferring the test inputs to cover all conditions, resulting in missing lines and branches. To tackle the problem, we propose decomposing the focal methods into slices and asking the LLM to generate test cases slice by slice. Our method simplifies the analysis scope, making it easier for the LLM to cover more lines and branches in each slice. We build a dataset comprising complex focal methods collected from the projects used by existing state-of-the-art approaches. Our experiment results show that our method significantly outperforms current test case generation methods with LLMs and the typical SBST method Evosuite regarding both line and branch coverage scores.CCS CONCEPTS\u2022 Software and its engineering \u2192 Software testing and debugging; \u2022 Computing methodologies \u2192 Natural language processing."
}