{
    "id": "20e144ee43a3a42dfb0a549c5e00bf151d853cbc",
    "title": "Adversarial Training with Rectified Rejection",
    "abstract": "Adversarial training (AT) is one of the most effective strategies for promoting model robustness, whereas even the state-of-the-art adversarially trained models struggle to exceed 65% robust test accuracy on CIFAR-10 without additional data, which is far from practical. A natural way to improve beyond this accuracy bottleneck is to introduce a rejection option, where con\ufb01dence is a commonly used certainty proxy. However, the vanilla con\ufb01dence can overestimate the model certainty if the input is wrongly classi\ufb01ed. To this end, we propose to use true con\ufb01dence (T-Con) (i.e., predicted probability of the true class) as a certainty oracle, and learn to predict T-Con by rectifying con\ufb01dence. Intriguingly, we prove that under mild conditions, a recti\ufb01ed con\ufb01dence (R-Con) rejector and a con\ufb01dence rejector can be coupled to distinguish any wrongly classi\ufb01ed input from correctly classi\ufb01ed ones. We also quantify that training R-Con to be aligned with T-Con could be an easier task than learning robust classi\ufb01ers. In our experiments, we evaluate our recti\ufb01ed rejection (RR) module on CIFAR-10, CIFAR-10-C, and CIFAR-100 under several attacks, and demonstrate that the RR module is well compatible with different AT frameworks on improving robustness, with little extra computation. Code is available at https://github.com/P2333/Rectified-Rejection ."
}