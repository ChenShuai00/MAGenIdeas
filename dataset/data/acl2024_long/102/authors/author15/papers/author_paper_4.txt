{
    "id": "7925f16e76cf274c257570ed3aa0ab97638be7d1",
    "title": "Ask Again, Then Fail: Large Language Models\u2019 Vacillations in Judgment",
    "abstract": "We observe that current large language models often waver in their judgments when faced with follow-up questions, even if the original judgment was correct. This wavering presents a signi\ufb01cant challenge for generating reliable responses and building user trust. To comprehensively assess this issue, we introduce a F OLLOW - UP Q UESTIONING M ECHANISM along with two metrics to quantify this inconsistency, con\ufb01rming its widespread presence in current large language models. Furthermore, to mitigate this issue, we explore various prompting strategies for closed-source models, and develop a training-based framework U NWAVERING -FQ that teaches large language models to maintain their originally correct judgments through synthesized high-quality preference data. Our experimental re-sults con\ufb01rm the effectiveness of our framework and its ability to enhance the general capabilities of large language models."
}