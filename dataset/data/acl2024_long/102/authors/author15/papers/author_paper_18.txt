{
    "id": "e3445c8a71f3ee5455311edc25f6b42c5f211061",
    "title": "R EL -A.I.: An Interaction-Centered Approach To Measuring Human-LM Reliance",
    "abstract": "The reconfiguration of human-LM interactions from simple sentence completions to complex, multi-domain, humanlike engagements necessitates new methodologies to understand how humans choose to rely on LMs. In our work, we contend that reliance is influenced by numerous factors within the interactional context of a generation, a departure from prior work that used verbalized confidence (e.g., \u201cI\u2019m certain the answer is...\u201d ) as the key determinant of reliance. Here, we introduce R EL -A.I. (/ r@\"laI /), an in situ, system-level evaluation approach to measure human reliance on LM-generated epistemic markers (e.g., \u201cI think it\u2019s..\u201d, \u201cUndoubtedly it\u2019s...\u201d ). Using this methodology, we measure reliance rates in three emergent human-LM interaction settings: long-term interactions, anthropomorphic generations, and variable subject matter. Our findings reveal that reliance is not solely based on verbalized confidence but is significantly affected by other features of the interaction context. Prior interactions, anthropomorphic cues, and subject domain all contribute to reliance variability. An expression such as, \u201cI\u2019m pretty sure it\u2019s...\u201d , can vary up to 20% in reliance frequency depending on its interactional context. Our work underscores the importance of context in understanding human reliance and offers future designers and researchers with a methodology to conduct such measurements."
}