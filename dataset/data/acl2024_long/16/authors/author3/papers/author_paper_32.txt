{
    "id": "532f32be1e918d6b75650947318e57fc8f4fb415",
    "title": "CodeRetriever: Unimodal and Bimodal Contrastive Learning",
    "abstract": "In this paper, we propose the CodeRetriever 001 model, which combines the unimodal and bi-002 modal contrastive learning to train function-003 level code semantic representations, specif-004 ically for the code search task. For uni-005 modal contrastive learning, we design a 006 semantic-guided method to build positive code 007 pairs based on the documentation and func-008 tion name. For bimodal contrastive learn-009 ing, we leverage the documentation and in-010 line comments of code to build text-code 011 pairs. Both contrastive objectives can fully 012 leverage the large-scale code corpus for pre-013 training. Experimental results on several pub-014 lic benchmarks, (i.e., CodeSearch, CoSQA, 015 etc.) demonstrate the effectiveness of CodeRe-016 triever in the zero-shot setting. By \ufb01ne-tuning 017 with domain/language speci\ufb01ed downstream 018 data, CodeRetriever achieves the new state-of-019 the-art performance with signi\ufb01cant improve-020 ment over existing code pre-trained models. 021 We will make the code, model checkpoint, and 022 constructed datasets publicly available. 023"
}