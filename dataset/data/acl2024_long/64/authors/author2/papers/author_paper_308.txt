{
    "id": "487e32a081fd40ea93b28f2acfdaa18b163c0cf7",
    "title": "LSTM-RNN MULTI-LEVEL ALIGNER DECODERENCODER Aligner LSTM-RNN LSTM-RNN LSTM-RNN go forward two segments to the end of the hall E World State Action Sequence Instruction",
    "abstract": "We propose a neural sequence-to-sequence model for direction following, a task that is essential to realizing effective autonomous agents. Our alignment-based encoder-decoder model with long short-term memory recurrent neural networks (LSTM-RNN) translates natural language instructions to action sequences based upon a representation of the observable world state. We introduce a multi-level aligner that empowers our model to focus on sentence \u201cregions\u201d salient to the current world state by using multiple abstractions of the input sentence. In contrast to existing methods, our model uses no specialized linguistic resources (e.g., parsers) or taskspecific annotations (e.g., seed lexicons). It is therefore generalizable, yet still achieves the best results reported to-date on a benchmark single-sentence dataset and competitive results for the limited-training multi-sentence setting. We analyze our model through a series of ablations that elucidate the contributions of the primary components of our model."
}