{
    "id": "b1db8ec14beb1b7e5d6300392be48b0f5b27ddeb",
    "title": "transcription Knowledge Extraction Graph Attention Link Prediction Text Attention Knowledge Extraction Entity Retrieval Background Knowledge Graphs Contextual Sentences Salient Entities Old Papers Existing Paper Reading Enriched Knowledge Graphs",
    "abstract": "We present a PaperRobot who performs as an automatic research assistant by (1) conducting deep understanding of a large collection of human-written papers in a target domain and constructing comprehensive background knowledge graphs (KGs); (2) creating new ideas by predicting links from the background KGs, by combining graph attention and contextual text attention; (3) incrementally writing some key elements of a new paper based on memory-attention networks: from the input title along with predicted related entities to generate a paper abstract, from the abstract to generate conclusion and future work, and finally from future work to generate a title for a follow-on paper. Turing Tests, where a biomedical domain expert is asked to compare a system output and a human-authored string, show PaperRobot generated abstracts, conclusion and future work sections, and new titles are chosen over human-written ones up to 30%, 24% and 12% of the time, respectively.1"
}