{
    "id": "bd9ba81bb31d2534d1ad388f9f7ef77a2ac08922",
    "title": "University of Lethbridge's Participation in TREC 2007 QA Track",
    "abstract": "Question Answering (QA) is retrieving answers to natural language questions from a collection of documents rather than retrieving relevant documents containing the keywords of the query which is performed by search engines. What a user usually wants is often a precise answer to a question. For example, given the question \u201cWho won the nobel prize in peace in 2006?\u201d what a user really wants is the answer \u201cDr. Muhammad Yunus\u201d, in stead of reading through lots of documents that contain the words \u201cwin\u201d, \u201cnobel\u201d,\u201cprize\u201d, \u201cpeace\u201d and \u201c2006\u201d etc. This means that question answering systems will possibly be integral to the next generation of search engines. The Text Retrieval Conference, TREC1 QA track is the major large-scale evaluation environment for open-domain question answering systems. The questions in the TREC-2007 QA track are clustered by target, which is the overall theme or topic of the questions. The track has three types of questions: 1. factoid that require only one correct response, 2. list that require a non redundant list of correct responses and 3. other questions that require a non redundant list of facts about the target that has not already been discovered by a previous answer. We took the approach of designing a question answering system that is based on document tagging and question classification. Question classification extracts useful information (i.e. answer type) from the question about how to answer the question. Document tagging extracts useful information from the documents, which will be used in finding the answer to the question. We used different available tools to tag the documents. Our system classifies the questions using manually developed rules."
}