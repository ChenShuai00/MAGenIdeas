{
    "id": "7ff5f121eb8aeec2f436d7bd4f39c759f62914ee",
    "title": "Augmenting Dialogue Response Generation With Unstructured Textual Knowledge",
    "abstract": "The dialogue response generation is a challenging task in chatbot applications. Recently neural-network-based dialogue models, including the sequence-to-sequence model and the RNN language models, are able to generate fluent and grammatically compliant responses, while there is a major limitation that most of the responses generated by these models are of chit-chat style instead of being informative. After investigating the currently used models, we found that one primary challenge is to model and generate informative words, such as named entities, especially when the entities have sparsely existed in training corpus. To address this problem, we propose to augment neural network-based generative architecture with knowledge embedding and knowledge attentive reader to incorporate external textual knowledge into the dialogue model to facilitate the dialogue modeling and generation. We evaluate the model with the Ubuntu dataset through automatic evaluation metrics and human evaluation. The experimental study has shown our methods outperform strong baselines in multiple metrics. We also visualize how the attention works in the dialogue context to verify the effectiveness of knowledge attentive reader mechanism."
}