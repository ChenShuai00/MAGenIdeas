{
    "id": "a9da568c4e7457323a3dbfb8b452b1ce6a1e306d",
    "title": "On Imitating Proprietary Language Models",
    "abstract": "Fine-tuned language models (LMs) provide the backbone for popular services such as ChatGPT, GitHub Copilot, and Cohere AI. The competitive edge of these systems often arises from their proprietary \ufffd netuning data (e.g., user-submitted prompts), and thus companies invest substantial resources into collecting and protecting this data. In this work, we study model \u201cimitation\u201d as a method to close the gap between open-source LMs and their closed-source counterparts. In the \ufffd rst part, we propose a framework for cheaply imitating proprietary language models in speci \ufffd c domains. In particular, we create a prompting pipeline that \ufffd rst asks what tasks a particular LM can solve and then asks for input-output examples for those tasks. We then \ufffd ne-tune open-source LMs on these supervised input-output examples to create imitation models. We show that human evaluators rate the outputs of these imitation models more highly as these models get larger and use bigger querying budgets. In the second part, we apply this general framework to ChatGPT and release Koala, our strongest imitation model. Initial evaluations show that this model results in impressive qualitative performance compared to ChatGPT in speci \ufffd c domains."
}