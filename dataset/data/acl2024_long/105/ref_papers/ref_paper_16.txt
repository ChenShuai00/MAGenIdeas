{
    "id": "7b6c820bb587ed1da281ca3f0a2e8df9d3de6f6d",
    "title": "Reinforcement Learning for Personalized Dialogue Management",
    "abstract": "Language systems have been of great interest to the research community and have recently reached the mass market through various assistant platforms on the web. Reinforcement Learning methods that optimize dialogue policies have seen successes in past years and have recently been extended into methods that personalizethe dialogue, e.g. take the personal context of users into account. These works, however, are limited to personalization to a single user with whom they require multiple interactions and do not generalize the usage of context across users. This work introduces a problem where a generalized usage of context is relevant and proposes two Reinforcement Learning (RL)-based approaches to this problem. The first approach uses a single learner and extends the traditional POMDP formulation of dialogue state with features that describe the user context. The second approach segments users by context and then employs a learner per context. We compare these approaches in a benchmark of existing non-RL and RL-based methods in three established and one novel application domain of financial product recommendation. We compare the influence of context and training experiences on performance and find that learning approaches generally outperform a handcrafted gold standard. CCS CONCEPTS \u2022 Computing methodologies \u2192 Reinforcement learning; Discourse, dialogue and pragmatics; \u2022 Human-centered computing \u2192 Natural language interfaces."
}