{
    "id": "9b65efdf5854fa7b55842fad3ec2ece7a9073e68",
    "title": "Deep Adversarial Robustness",
    "abstract": "Deep learning has recently contributed to learning state-of-the-art representations in service of various image recognition tasks. Deep learning uses cascades of many layers of nonlinear processing units for feature extraction and transformation. Recently, researchers have shown that deep learning architectures are particularly vulnerable to adversarial examples, inputs to machine learning models intentionally designed to cause the model to make a mistake [2]. In this paper, we propose three methods for increasing the robustness of deep learning architectures against adversarial examples. Specifically, we propose a biologically inspired multi-task learning (MTL) model, a downsampling model, and a model trained on images created by the generator from a generative adversarial network. Our results show that using these models improve adversarial robustness against universal adversarial perturbations [5]. Additionally, we present a metric for adversarial robustness and provide extensive analysis on how adversarial images are represented in image vector space."
}