{
    "id": "71fe2b526fc1a2bfc1d91df9711e9d6654035479",
    "title": "Defending Textual Neural Networks against Black-Box Adversarial Attacks with Stochastic Multi-Expert Patcher",
    "abstract": "Even though several methods have proposed 001 to defend textual neural network (NN) models 002 against black-box adversarial attacks, they of- 003 ten defend against a speci\ufb01c text perturbation 004 strategy and/or require re-training the models 005 from scratch. This leads to a lack of general- 006 ization in practice and redundant computation. 007 In particular, the state-of-the-art transformer 008 models (e.g., BERT, RoBERTa) require great 009 time and computation resources. By borrow- 010 ing an idea from software engineering , in or- 011 der to address these limitations, we propose 012 a novel algorithm, S HIELD , which modi\ufb01es 013 and re-trains only the last layer of a textual 014 NN, and thus it \u201cpatches\u201d and \u201ctransforms\u201d 015 the NN into a stochastic weighted ensemble 016 of multi-expert prediction heads. Consider- 017 ing that most of current black-box attacks rely 018 on iterative search mechanisms to optimize 019 their adversarial perturbations, S HIELD con- 020 fuses the attackers by automatically utilizing 021 different weighted ensembles of predictors de- 022 pending on the input. In other words, S HIELD 023 breaks a fundamental assumption of the attack, 024 which is a victim NN model remains constant 025 during an attack. By conducting comprehen- 026 sive experiments, we demonstrate that all of 027 CNN, RNN, BERT, and RoBERTa-based tex- 028 tual NNs, once patched by S HIELD , exhibit 029 a relative enhancement of 15%\u201370% in accu- 030 racy on average against 14 different black-box 031 attacks, outperforming 6 defensive baselines 032 across 3 public datasets. All codes are to be 033 released. 034"
}