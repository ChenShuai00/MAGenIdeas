{
    "id": "6cf971fcbfca1e7b4a851890408b7f56127fb792",
    "title": "CL-ReKD: Cross-lingual Knowledge Distillation for Multilingual Retrieval Question Answering",
    "abstract": "Cross-Lingual Retrieval Question Answering 001 (CL-ReQA) is concerned with retrieving an-002 swer documents or passages to a question writ-003 ten in a different language. A common ap-004 proach to CL-ReQA is to create a multilingual 005 sentence embedding space such that question-006 answer pairs across different languages are 007 close to each other. In this paper, we propose 008 a novel CL-ReQA method utilizing the con-009 cept of knowledge distillation and a new cross-010 lingual consistency training technique to cre-011 ate a multilingual embedding space for ReQA. 012 To assess the effectiveness of our work, we 013 conducted comprehensive experiments on CL-014 ReQA and a downstream task, machine read-015 ing QA. We compared our proposed method 016 with the current state-of-the-art solutions across 017 three public CL-ReQA corpora. Our method 018 outperforms competitors in 19 out of 21 set-019 tings of CL-ReQA. When used with a down-020 stream machine reading QA task, our method 021 outperforms the best existing language-model-022 based method by 10% in F1 while being 10 023 times faster in sentence embedding computa-024 tion. 025"
}