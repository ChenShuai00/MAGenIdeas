{
    "id": "160d6387db2d52544cc5b9db4a97b20b783974b4",
    "title": "IMPLI : Investing NLI Models\u2019 Performance on Figurative Language",
    "abstract": "Natural language inference (NLI) has been 001 widely used as a task to train and evaluate 002 models for language understanding. However, 003 the ability of NLI models to perform infer-004 ences that require understanding of \ufb01gurative 005 languages such as idioms and metaphors re-006 mains understudied. We introduce the IMPLI 007 ( I diomatic and M etaphoric P aired L anguage 008 I nference) dataset consisting of over 25K 009 semi-automatically generated and 1.5K hand-010 written English sentence pairs based on id-011 iomatic and metaphoric phrases. We use 012 IMPLI to evaluate NLI models based on 013 RoBERTa \ufb01ne-tuned on the MNLI dataset, 014 and show that while they can reliably de-015 tect entailment relationship between \ufb01gurative 016 phrases with their literal de\ufb01nition, they per-017 form poorly on examples where the phrases 018 are designed to not entail the paired de\ufb01nition. 019 This dataset suggests the limits of current NLI 020 models with regard to understanding \ufb01gurative 021 language and provides a benchmark for future 022 improvements in this direction. 1 023"
}