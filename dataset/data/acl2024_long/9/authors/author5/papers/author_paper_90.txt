{
    "id": "705a01bf1afaf245cc4117992ed54a28f847a93c",
    "title": "Rethinking News Text Classification from a Timeliness Perspective under the Pre-training and Fine-tuning Paradigm",
    "abstract": "Pre-trained language models (PLMs) have 001 made significant progress in NLP. News text 002 classification is one of the most fundamental 003 tasks in NLP, and various existing works have 004 shown that fine-tuned on PLMs could score up 005 to the accuracy of 98% on the target task. It 006 seems that this task has been well-addressed. 007 However, we discover that news timeliness can 008 cause a massive impact on the news text classifi-009 cation, which drops nearly 20% points from the 010 initial results. In this paper, we define timeli-011 ness issues in news classification and design the 012 experiment to measure the influence. Moreover, 013 we investigate several methods to recognize 014 and replace obsolete vocabularies. However, 015 the results show that it is difficult to eliminate 016 the impact of news timeliness from the words\u2019 017 perspective. In addition, we propose a set of 018 large-scale, time-sensitive news datasets to fa-019 cilitate the study of this problem. 020"
}