{
    "id": "ada01194e95945f8f54224f5e791476a4923362e",
    "title": "P NEG : Prompt-based Negative Response Generation for Robust Response Selection Model",
    "abstract": "Dialogue response selection models typically 001 predict an appropriate response relying on the 002 context-response content similarity. However, 003 the selection model with over-reliance only on 004 superficial features is vulnerable to adversar-005 ial responses that are semantically similar but 006 irrelevant to dialogue context. Recent studies 007 have shown that leveraging these adversarial 008 responses as negative training samples is useful 009 for improving the robustness of the selection 010 model. Nevertheless, existing methods often 011 require further fine-tuning for data creation or 012 have limited scalability. To overcome these 013 limitations, this paper proposes a simple but ef-014 fective method for generating adversarial nega-015 tive responses leveraging a large-scale language 016 model. Our method can generate realistic nega-017 tive responses only with a few human-written 018 examples and a prompt designed to optimize 019 generation quality. Experimental results on the 020 dialogue selection task show that our method 021 outperforms existing methods for creating neg-022 ative responses. Synthetic quality analyses and 023 ablation studies prove that our method is scal-024 able and can generate high-quality negative re-025 sponses. These results suggest that our method 026 can be an effective alternative to human anno-027 tators in generating adversarial responses. 028"
}