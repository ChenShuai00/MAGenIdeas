{
    "id": "719a1e852ab3aff942c140508bb8045332b511ac",
    "title": "An Embarrassingly Simple Key Prompt Protection Mechanism for Large Language Models",
    "abstract": "Large language models (LLMs) have notably 001 revolutionized many domains within natural 002 language processing due to their exceptional 003 performance. Their security has become in-004 creasingly vital. This study is centered on pro-005 tecting LLMs against unauthorized access and 006 potential theft. We propose a simple yet ef-007 fective protective measure wherein a unique 008 key prompt is embedded within the LLM. This 009 mechanism enables the model to respond only 010 when presented with the correct key prompt; 011 otherwise, LLMs will refuse to react to any in-012 put instructions. This key prompt protection 013 offers a robust solution to prevent the unau-014 thorized use of LLMs, as the model becomes 015 unusable without the correct key. We evalu-016 ated the proposed protection on multiple LLMs 017 and NLP tasks. Results demonstrate that our 018 method can successfully protect the LLM with-019 out significantly impacting the model\u2019s original 020 function. Moreover, we demonstrate potential 021 attacks that attempt to bypass the protection 022 mechanism will adversely affect the model\u2019s 023 performance, further emphasizing the effective-024 ness of the proposed protection method. 025"
}