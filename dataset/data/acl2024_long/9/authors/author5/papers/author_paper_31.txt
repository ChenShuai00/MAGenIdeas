{
    "id": "2ab6782e8ac035801da96a47acd54c4c505ef3c1",
    "title": "ERNIE-Layout: Layout-Knowledge Enhanced Multi-modal Pre-training for Document Understanding",
    "abstract": "We propose ERNIE-Layout, a knowledge en-001 hanced pre-training approach for visual docu-002 ment understanding, which incorporates layout-003 knowledge into the pre-training of visual docu-004 ment understanding to learn a better joint multi-005 modal representation of text, layout and im-006 age. Previous works directly model serialized 007 tokens from documents according to a raster-008 scan order, neglecting the importance of the 009 reading order of documents, leading to sub-010 optimal performance. We incorporate layout-011 knowledge from Document-Parser into docu-012 ment pre-training, which is used to rearrange 013 the tokens following an order more consistent 014 with human reading habits. And we propose 015 the Reading Order Prediction (ROP) task to en-016 hance the interactions within segments and cor-017 relation between segments and a fine-grained 018 cross-modal alignment pre-training task named 019 Replaced Regions Prediction (RRP). ERNIE-020 Layout attempts to fuse textual and visual fea-021 tures in a unified Transformer model, which 022 is based on our newly proposed spatial-aware 023 disentangled attention mechanism. ERNIE-024 Layout achieves superior performance on vari-025 ous document understanding tasks, setting new 026 SOTA for four tasks, including information 027 extraction, document classification, document 028 question answering. 029"
}