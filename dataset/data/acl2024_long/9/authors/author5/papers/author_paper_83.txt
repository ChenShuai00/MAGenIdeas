{
    "id": "3d7f098d424489e8b58c776722efa4c01b797788",
    "title": "Can Pre-trained Models Really Generate Single-Step Textual Entailment?",
    "abstract": "We investigate the task of generating textual 001 entailment (GTE). Different from prior works 002 on recognizing textual entailment, also known 003 as NLI, GTE requires the models with deeper 004 reasoning capabilities - generating entailment 005 from premises rather than making prediction 006 on given premises and the entailment. We ar-007 gue that existing adapted datasets are limited 008 and inadequate to train and evaluate human-009 like reasoning in the GTE. In this paper, we 010 propose a new large-scale benchmark, named 011 SEG , targeted for learning and evaluating mod-012 els\u2019 capabilities towards RTE. SEG consists of 013 15k instances with each containing a pair of 014 premise statements and a human-annotated en-015 tailment. It is constructed by \ufb01rst retrieving 016 instances from a knowledge base, and then 017 augmenting each instance with several comple-018 mentary instances by 7 manually crafted trans-019 formations. We demonstrate that even exten-020 sively \ufb01ne-tuned pre-trained models perform 021 poorly on SEG . The best baseline can only gen-022 erate valid textual entailment for 59.1% cases. 023 Further, to motivate future advances, we pro-024 vide detailed analysis to show signi\ufb01cant gaps 025 between baselines and human performance. 026"
}