{
    "id": "db0b075451ec154d92bdffbec8f11101d2357e89",
    "title": "DAQE: Exploring the Direct Assessment on Word-Level Quality Estimation in Machine Translation",
    "abstract": "Word-level Quality Estimation (QE) of Ma-001 chine Translation (MT) helps to find out po-002 tential translation errors in translated sentences 003 without reference. The current collection of QE 004 datasets is typically based on the exact match-005 ing between the words from MT sentences and 006 post-edited sentences through a Translation Er-007 ror Rate (TER) toolkit. However, we find that 008 the data generated by TER cannot faithfully 009 reflect human judgment, which may make the 010 research deviate from the correct direction. To 011 overcome the limitation, we for the first time 012 collect the direct assessment (DA) dataset for 013 the word-level QE task, namely DAQE, which 014 is a golden corpus annotated by expert transla-015 tors on two language pairs. Furthermore, we 016 propose two tag correcting strategies, namely 017 tag refinement strategy and tree-based annota-018 tion strategy, to make the TER-based artificial 019 QE tags closer to human judgement, so that the 020 automatically corrected and large-scale TER-021 based data can be used to improve the QE per-022 formance by pre-training. We conduct detailed 023 experiments on our collected DAQE dataset, 024 as well as comparison with the TER-based QE 025 dataset MLQE-PE. The results not only show 026 our proposed dataset DAQE is more consistent 027 with human judgment but also confirm the ef-028 fectiveness of the tag correcting strategies. 1 029"
}