{
    "id": "e555837afb860a130d0fa9e11917cc80fa34ca5a",
    "title": "Bridge the Gap Between CV and NLP! Optimize Adversarial Texts in Continuous Space",
    "abstract": "Despite recent success on various tasks, deep 001 learning techniques still perform poorly on ad-002 versarial examples with small perturbations. 003 While optimization methods for adversarial at-004 tacks are well-explored in the \ufb01eld of com-005 puter vision, it is impractical to directly ap-006 ply them in natural language processing due 007 to the discrete nature of the text. To ad-008 dress the problem, we propose a uni\ufb01ed frame-009 work to extend the existing optimization-based 010 method in the vision domain to craft textual 011 adversarial samples. In this framework, con-012 tinuously optimized perturbations are added 013 to the embedding layer and ampli\ufb01ed in the 014 forward propagation process. Then the \ufb01nal 015 perturbed latent representations are decoded 016 with a masked language model head to obtain 017 potential adversarial samples. In this paper, 018 we instantiate our framework with an attack 019 algorithm named T extual P rojected G radient 020 D escent ( T-PGD ). We \ufb01nd our algorithm ef-021 fective even using proxy gradient information. 022 Therefore, we perform more challenging trans-023 fer black-box attacks and conduct comprehen-024 sive experiments to evaluate our attack algo-025 rithm with BERT, RoBERTa, and ALBERT 026 on three benchmark datasets. Experimental 027 results demonstrate that our method achieves 028 an overall better performance and produces 029 more \ufb02uent and grammatical adversarial sam-030 ples compared to strong baseline methods. All 031 the code and data will be made public. 032"
}