{
    "id": "6d88e3e38f0bad4e0acfe2cf333f004e6b59b09a",
    "title": "What Question Answering can Learn from Trivia Nerds",
    "abstract": "In addition to the traditional task of machines answering questions, question answering (QA) research creates interesting, challenging questions that help systems how to answer questions and reveal the best systems. We argue that creating a QA dataset\u2014and the ubiquitous leaderboard that goes with it\u2014closely resembles running a trivia tournament: you write questions, have agents (either humans or machines) answer the questions, and declare a winner. However, the research community has ignored the hard-learned lessons from decades of the trivia community creating vibrant, fair, and effective question answering competitions. After detailing problems with existing QA datasets, we outline the key lessons\u2014removing ambiguity, discriminating skill, and adjudicating disputes\u2014that can transfer to QA research and how they might be implemented."
}