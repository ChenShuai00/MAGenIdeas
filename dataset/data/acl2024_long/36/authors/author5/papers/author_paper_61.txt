{
    "id": "ebc3298c37b9363e295e7766b6dbdd60a174ac8f",
    "title": "Identifying Objective and Subjective Words via Topic Modeling",
    "abstract": "It is observed that distinct words in a given document have either strong or weak ability in delivering facts (i.e., the <italic>objective</italic> sense) or expressing opinions (i.e., the <italic>subjective</italic> sense) depending on the topics they associate with. Motivated by the intuitive assumption that different words have varying degree of <italic>discriminative</italic> power in delivering the objective sense or the subjective sense with respect to their assigned topics, a model named as <inline-formula> <tex-math notation=\"LaTeX\">${i}$ </tex-math></inline-formula>dentified <inline-formula> <tex-math notation=\"LaTeX\">${o}$ </tex-math></inline-formula>bjective\u2013<inline-formula> <tex-math notation=\"LaTeX\">${s}$ </tex-math></inline-formula>ubjective latent Dirichlet allocation (LDA) (<inline-formula> <tex-math notation=\"LaTeX\">${i}$ </tex-math></inline-formula>osLDA) is proposed in this paper. In the <inline-formula> <tex-math notation=\"LaTeX\">${i}$ </tex-math></inline-formula>osLDA model, the simple P\u00f3lya urn model adopted in traditional topic models is modified by incorporating it with a probabilistic generative process, in which the novel \u201c<italic>Bag-of-Discriminative-Words</italic>\u201d (BoDW) representation for the documents is obtained; each document has two different BoDW representations with regard to objective and subjective senses, respectively, which are employed in the joint objective and subjective classification instead of the traditional Bag-of-Topics representation. The experiments reported on documents and images demonstrate that: 1) the BoDW representation is more predictive than the traditional ones; 2) <inline-formula> <tex-math notation=\"LaTeX\">${i}$ </tex-math></inline-formula>osLDA boosts the performance of topic modeling via the joint discovery of latent topics and the different objective and subjective power hidden in every word; and 3) <inline-formula> <tex-math notation=\"LaTeX\">${i}$ </tex-math></inline-formula>osLDA has lower computational complexity than supervised LDA, especially under an increasing number of topics."
}