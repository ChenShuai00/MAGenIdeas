{
    "id": "d5ccb7ae5f596560a1b797a7f7e03469a63da519",
    "title": "HuatuoGPT, Towards Taming Language Models To Be a Doctor",
    "abstract": "In this paper, we present HuatuoGPT, a Large Language Model (LLM) for medical consulta-tion. The core recipe of HuatuoGPT is to leverage both distilled data from ChatGPT and real-world data from doctors in the supervised fine-tuning stage. This is not only because purely using ChatGPT -distilled data might cause \u2018model collapse\u2019, but also because real-world data from doctors would be complementary to ChatGPT -distilled data. The responses from ChatGPT are usually detailed, well-presented, fluent, and instruction-followed, but it cannot perform like a doctor in many aspects, e.g. for interactive diagnosis. Therefore, the extra doctors\u2019 data could tame a distilled language model to perform like doctors. To synergize the strengths of both data sources, we introduce RLMF (Reinforcement Learning from Mixed Feedback) where a reward model is trained to align the language model with the merits that both sources (ChatGPT and doctors) bring. Experimental results (in GPT-4 evaluation, human evaluation, and medical benchmark datasets) demonstrate that HuatuoGPT achieves state-of-the-art results in performing medical consulta-tion"
}