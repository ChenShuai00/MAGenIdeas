{
    "id": "7b0f98f51040700aae3cd9f0e3432dedcd69fb30",
    "title": "When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories",
    "abstract": "Despite their impressive performance on diverse tasks, large language models (LMs) still struggle with tasks requiring rich world knowledge, implying the limitations of relying solely on their parameters to encode a wealth of world knowledge. This paper aims to understand LMs\u2019 strengths and limitations in memorizing factual knowledge, by conducting large-scale knowledge probing experiments of 10 models and 4 augmentation meth-ods on P OP QA, our new open-domain QA dataset with 14k questions. We \ufb01nd that LMs struggle with less popular factual knowledge, and that scaling fails to appreciably improve memorization of factual knowledge in the tail. We then show that retrieval-augmented LMs largely outperform orders of magnitude larger LMs, while unassisted LMs remain competitive in questions about high-popularity entities. Based on those \ufb01ndings, we devise a simple, yet effective, method for powerful and ef\ufb01cient retrieval-augmented LMs, which re-trieves non-parametric memories only when necessary. Experimental results show that this signi\ufb01cantly improves models\u2019 performance while reducing the inference costs. 1"
}