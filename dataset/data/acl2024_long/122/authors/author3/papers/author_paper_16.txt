{
    "id": "cd9854d231def5c1b6ddc6d53efd40c963fc3f7e",
    "title": "M ANGO : Enhancing the Robustness of VQA Models via Adversarial Noise Generation",
    "abstract": "Large-scale pre-trained vision-and-language 001 (V+L) transformers have propelled the state 002 of the art (SOTA) on Visual Question Answer-003 ing (VQA) task. Despite impressive perfor-004 mance on the standard VQA benchmark, it re-005 mains unclear how robust these models are. To 006 investigate, we conduct a host of evaluations 007 over 4 different types of robust VQA datasets: 008 ( i ) Linguistic Variation; ( ii ) Logical Reason-009 ing; ( iii ) Visual Content Manipulation; and 010 ( iv ) Answer Distribution Shift. Experiments 011 show that pre-trained V+L models already ex-012 hibit better robustness than many task-specific 013 SOTA methods via standard model finetun-014 ing. To further enhance model robustness, we 015 propose M ANGO , a generic and efficient ap-016 proach that learns a M ultimodal A dversarial 017 N oise G enerat O r in the embedding space to 018 fool V+L models. Differing from previous 019 studies focused on one specific type of robust-020 ness, M ANGO is agnostic to robustness types, 021 and enables universal performance lift for both 022 task-specific and pre-trained models over di-023 verse robust VQA datasets designed to evaluate 024 broad aspects of robustness. Comprehensive 025 experiments demonstrate that M ANGO outper-026 forms previous task-specific SOTAs on 7 out 027 of 9 robustness benchmarks. 028"
}