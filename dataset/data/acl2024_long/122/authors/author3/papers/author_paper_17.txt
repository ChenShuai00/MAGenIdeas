{
    "id": "fdf1dfa577d7486d29eebea3235d67237f70a886",
    "title": "Towards Linguistically Robust NLG Systems for Localized Virtual Assistants",
    "abstract": "One of the biggest challenges for localizing 001 the natural language generation of virtual as-002 sistants like Alexa, the Google Assistant, or 003 Siri, to many languages, is the proper handling 004 of entities. Neural machine translation sys-005 tems may translate entities literally, or intro-006 duce grammar mistakes by using the wrong in-007 \ufb02ections. The diversity of linguistic phenom-008 ena for entities across all languages is vast, yet 009 ensuring grammatical correctness for a broad 010 diversity of entities is critical \u2014 native speak-011 ers may \ufb01nd entity-related grammatical errors 012 silly, jarring, or even offensive. 013 To assess linguistic robustness, we create a 014 multilingual corpus of linguistically signi\ufb01-015 cant entities annotated by linguist experts. We 016 also share a simple algorithm for how to lever-017 age this corpus to produce linguistically di-018 verse training and evaluation datasets. Using 019 the Schema-Guided Dialog Dataset (DSTC8) 020 as a test bed, we collect human translations for 021 a subset of linguistically boosted examples to 022 establish quality baselines for neural, template-023 based, and hybrid NLG systems in French 024 (high-resource), Marathi (low-resource), and 025 Russian (highly in\ufb02ected language). We make 026 our corpus and the derived translation-based 027 datasets available for further research. 028"
}