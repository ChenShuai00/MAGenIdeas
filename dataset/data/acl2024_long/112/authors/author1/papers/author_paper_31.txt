{
    "id": "f1b5827e848ec4c1b004cfd1d42cb79b1cb729ff",
    "title": "Cross-lingual Transfer Learning for Intent Detection of Covid-19 Utterances",
    "abstract": "In times of a global pandemic, interactive chat bots are an indispensable tool to provide information to people. With this motivation, we study the problem of intent detection of user utterances, which is usually the \ufb01rst language understanding step in such systems. Speci\ufb01-cally, we focus on cross-lingual transfer learning for intent detection of user utterances and zero-shot learning for code-switched (CS) utterances. We release a multilingual dataset, M-CID, containing 6871 utterances across English, Spanish, French, German and Spanglish (Spanish + English). We use this dataset to explore some cross-lingual transfer learning techniques to study: (1) monolingual and multilingual model baselines, (2) cross-lingual transfer from English to Spanish, French and German, and (3) zero-shot code-switching for Span-glish. In our experiments, we observe that XLM-R models are able to signi\ufb01cantly out-perform cross lingual word embedding techniques for all of the above settings. We also show that it is possible to obtain a strong performance on code-switched data by only using monolingual data from substrate languages."
}