{
    "id": "a210df43018c682f6f57120cdb66b93a42c26699",
    "title": "Probing Causal Common Sense in Dialogue Response Generation",
    "abstract": "Communication is a cooperative effort that requires reaching mutual understanding among the participants. Humans use commonsense reasoning implicitly to produce natural and logically-coherent responses. As a step towards \ufb02uid human-AI communication, we study if response generation (RG) models can emulate human reasoning process and use common sense to help produce better-quality responses. We aim to tackle two research questions: how to formalize conversational common sense and how to examine RG models capability to use common sense? We \ufb01rst propose a task, CEDAR : C ausal common s E nse in D i A logue R esponse generation, that concretizes common sense as textual explanations for what might lead to the response and evaluates RG models behavior by comparing the modeling loss given a valid explanation with an invalid one. Then we introduce a process that automatically generates such explanations and ask humans to verify them. Finally, we design two probing settings for RG models targeting two reasoning capabilities using veri\ufb01ed explanations. We \ufb01nd that RG models have a hard time determining the logical validity of explanations but can identify grammatical naturalness of the explanation easily. 1"
}