{
    "id": "4a8fe7ecf225e5bada08642fcd77d3cbb322b967",
    "title": "Human Emotion Knowledge Representation Emerges in Large Language Model and Supports Discrete Emotion Inference",
    "abstract": "How humans infer discrete emotions is a fundamental research question in the field of psychology. While conceptual knowledge about emotions (emotion knowledge) has been suggested to be essential for emotion inference, evidence to date is mostly indirect and inconclusive. As the large language models (LLMs) have been shown to support effective representations of various human conceptual knowledge, the present study further employed artificial neurons in LLMs to investigate the mechanism of human emotion inference. With artificial neurons activated by prompts, the LLM (RoBERTa) demonstrated a similar conceptual structure of 27 discrete emotions as that of human behaviors. Furthermore, the LLM-based conceptual structure revealed a human-like reliance on 14 underlying conceptual attributes of emotions for emotion inference. Most importantly, by manipulating attribute-specific neurons, we found that the corresponding LLM's emotion inference performance deteriorated, and the performance deterioration was correlated to the effectiveness of representations of the conceptual attributes on the human side. Our findings provide direct evidence for the emergence of emotion knowledge representation in large language models and suggest its casual support for discrete emotion inference. # These authors contributed equally: liming16@tsinghua.org.cn, yushengsu.thu@gmail.com * Corresponding authors: {liuzy, dzhang}@tsinghua.edu.cn The source code can be obtained from https://github.com/thunlp/Model_Emotion."
}