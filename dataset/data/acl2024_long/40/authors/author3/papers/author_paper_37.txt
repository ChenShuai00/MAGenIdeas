{
    "id": "a5b7e10b1eb7c31b312b7c27444549374859355c",
    "title": "Semantic Role Labeling with Pretrained Language Models for Known and Unknown Predicates",
    "abstract": "We build the first full pipeline for semantic role labelling of Russian texts. The pipeline implements predicate identification, argument extraction, argument classification (labeling), and global scoring via integer linear programming. We train supervised neural network models for argument classification using Russian semantically annotated corpus \u2013 FrameBank. However, we note that this resource provides annotations only to a very limited set of predicates. We combat the problem of annotation scarcity by introducing two models that rely on different sets of features: one for \u201cknown\u201d predicates that are present in the training set and one for \u201cunknown\u201d predicates that are not. We show that the model for \u201cunknown\u201d predicates can alleviate the lack of annotation by using pretrained embeddings. We perform experiments with various types of embeddings including the ones generated by deep pretrained language models: word2vec, FastText, ELMo, BERT, and show that embeddings generated by deep pretrained language models are superior to classical shallow embeddings for argument classification of both \u201cknown\u201d and \u201cunknown\u201d predicates."
}