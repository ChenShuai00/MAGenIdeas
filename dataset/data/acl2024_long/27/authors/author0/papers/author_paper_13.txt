{
    "id": "b5e8e0f65258e40e0fde9ef66cabc4178f22a0a0",
    "title": "Does D ETECT GPT Fully Utilize Perturbation? Selective Perturbation on Model-Based Contrastive Learning Detector would be Better",
    "abstract": "The burgeoning capabilities of large language models (LLMs) have raised growing concerns about abuse. DetectGPT (Mitchell et al., 2023), a zero-shot metric-based unsupervised machine-generated text detector, first introduces perturbation and shows great performance improvement. However, DetectGPT\u2019s random perturbation strategy might introduce noise, limiting the distinguishability and further performance improvements. Moreover, its logit regression module relies on setting the threshold, which harms the generalizability and applicability of individual or small-batch inputs. Hence, we propose a novel detector, P ECOLA , which uses selective strategy perturbation to relieve the important information loss caused by random masking, and multi-pair contrastive learning to capture the implicit pattern information during perturbation, facilitating few-shot performance. The experiments show that P ECOLA outperforms the SOTA method by 1.20% in accuracy on average on four public datasets. We further analyze the effectiveness, robustness, and generalization of our perturbation method."
}