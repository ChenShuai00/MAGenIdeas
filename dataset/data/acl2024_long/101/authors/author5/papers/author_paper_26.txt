{
    "id": "ef2d9e04d3225c7b15c64fd30d90af858036647c",
    "title": "A Well-Composed Text is Half Done! Semantic Composition Sampling for Diverse Conditional Generation",
    "abstract": "We propose Composition Sampling, a simple 001 but effective method to generate higher qual-002 ity diverse outputs for conditional generation 003 tasks, compared to previous stochastic decod-004 ing strategies. It builds on recently proposed 005 planning-based neural generation models that 006 are trained to \ufb01rst create a composition of the 007 output using an entity chain and then continue 008 to generate conditioned on the entity chain 009 and the input (Narayan et al., 2021). Our ap-010 proach avoids text degeneration by \ufb01rst sam-011 pling a composition in the form of an entity 012 chain and then using beam search to gener-013 ate the best possible text grounded to the en-014 tity chain. Experiments on CNN/DailyMail 015 and XSum using a variety of automatic metrics 016 and human-based evaluation demonstrate that 017 Composition Sampling is currently the best 018 available decoding strategy for generating di-019 verse meaningful summaries. We further out-020 perform state-of-the-art approaches for ques-021 tion generation in terms of BLEU. 022"
}