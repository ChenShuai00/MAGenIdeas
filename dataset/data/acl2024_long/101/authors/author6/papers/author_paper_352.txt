{
    "id": "b2a164d3faa254b1a2b0058f540b22226c2a9565",
    "title": "Edinburgh Research Explorer Explainability and hate speech Structured explanations make social media moderators faster",
    "abstract": "Content moderators play a key role in keeping the conversation on social media healthy. While the high volume of content they need to judge represents a bottleneck to the moderation pipeline, no studies have explored how models could support them to make faster decisions. There is, by now, a vast body of research into detecting hate speech, sometimes explicitly motivated by a desire to help improve content moderation, but published research us-ing real content moderators is scarce. In this work we investigate the effect of explanations on the speed of real-world moderators. Our experiments show that while generic explanations do not affect their speed and are often ignored, structured explanations lower moderators\u2019 decision making time by 7.4%."
}