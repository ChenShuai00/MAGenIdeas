{
    "id": "4e23271a9d79ee41f5056db2af0cb20cf9bdba17",
    "title": "Improving Coherence of Language Model Generation with Latent Semantic State",
    "abstract": "Sentences generated by neural language mod-001 els (LMs) often suffer from coherence errors: 002 they describe events and situations inconsistent 003 with the state of the world described by pre-004 ceding text. We show that coherence errors can 005 arise at multiple stages of LM computation, and 006 describe a procedure for distinguishing errors 007 in inferring state from errors in generating sen-008 tences . In models with correctable errors of the 009 first type, we show that targeted supervision can 010 address them. We introduce two procedures for 011 using explicit representations of world state as 012 auxiliary supervision. These procedures effi-013 ciently improve LM coherence, in some cases 014 providing the benefits of 1,000\u20139,000 training 015 examples with only 500 state annotations. 016"
}