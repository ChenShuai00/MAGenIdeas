{
    "id": "f9cd110f9f020a9e5345aa3f565c7266985ca4ee",
    "title": "QAMPARI: : An Open-domain Question Answering Benchmark for Questions with Many Answers from Multiple Paragraphs",
    "abstract": "Existing benchmarks for open-domain question answering (ODQA) typically focus on questions whose answers can be extracted from a single paragraph. By contrast, many natural questions, such as \u201cWhat players were drafted by the Brooklyn Nets?\u201d have a list of answers . Answering such questions requires retrieving and reading from many passages, in a large corpus. We introduce QAMP AR I, an ODQA benchmark, where question answers are lists of entities, spread across many para-graphs. We created QAMP AR I by (a) generating questions with multiple answers from Wikipedia\u2019s knowledge graph and tables, (b) automatically pairing answers with supporting evidence in Wikipedia paragraphs, and (c) manually paraphrasing questions and validating each answer. We train ODQA models from the retrieve-and-read family and \ufb01nd that QAMP AR I is challenging in terms of both passage retrieval and answer generation, reaching an F 1 score of 26.6 at best. Our results high-light the need for developing ODQA models that handle a broad range of question types, including single and multi-answer questions."
}