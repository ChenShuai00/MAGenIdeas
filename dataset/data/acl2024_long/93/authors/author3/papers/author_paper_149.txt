{
    "id": "38ff190965e0438c8d8f0e562628986c2064c8b6",
    "title": "Memory placement in network compression: Line and grid topologies",
    "abstract": "Enabling intermediate nodes in networks with the capability of storing the past communication can offer several benefits. Recently, we have shown that by utilizing memory at intermediate nodes, one can compress the data stream sent from the source node with superior performance compared to the conventional end-to-end compression of individual sequences destined to each client. In other words, memorization or learning of past traffic at intermediate nodes provide extra compression gain. This gain comes from the fact that utilizing previous traffic shared between the source and intermediate nodes with memory helps to close the gap between the compression performance of universal compression techniques and entropy of each individual sequence. The gain of data traffic reduction depends on the number of memory units and their locations. Since in practical scenarios only a select number of nodes have the storage and computational capability to function as a memory unit, it is important to find the optimal location for such nodes. Furthermore, memory placement in the network poses some challenges to traditional shortest path routing algorithms, as the shortest path is not necessarily minimum cost route in networks with memory. In this paper, we investigate the memory placement problem and routing algorithms for networks featuring memory units for network compression. We derive the optimal memory placement strategy on line and grid networks. We further demonstrate how conventional routing algorithms should be modified when there are memory units in the network."
}