{
    "id": "bd22e78d956d2e06d9f192ddbbe414adeb791717",
    "title": "User Embedding Model for Personalized Language Prompting",
    "abstract": "Modeling long user histories plays a pivotal role in enhancing recommendation systems, allowing to capture users\u2019 evolving preferences, resulting in more precise and personalized recommendations. In this study, we tackle the challenges of modeling long user histories for preference understanding in natural language. Specifically, we introduce a new User Embedding Module (UEM) that efficiently processes user history in free-form text by compressing and representing them as embeddings, to use them as soft prompts to a language model (LM). Our experiments demonstrate the superior capability of this approach in handling significantly longer histories compared to conventional text-based methods, yielding substantial improvements in predictive performance. Models trained using our approach exhibit substantial enhancements, with up to 0.21 and 0.25 F1 points improvement over the text-based prompting baselines. The main contribution of this research is to demonstrate the ability to bias language models via user signals."
}