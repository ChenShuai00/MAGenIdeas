{
    "id": "122c47331cec3427efd6bb613e43bee31e931a1a",
    "title": "Contextual information integration for stance detection via cross-attention",
    "abstract": "Stance detection deals with the identi\ufb01cation of an author\u2019s stance towards a target and is applied on various text domains like social media and news. In many cases, inferring the stance is challenging due to insuf\ufb01cient access to contextual information. Complementary context can be found in knowledge bases but integrating the context into pretrained language models is non-trivial due to their graph structure. In contrast, we explore an approach to integrate contextual information as text which aligns better with transformer architectures. Speci\ufb01cally, we train a model consisting of dual encoders which exchange information via cross-attention. This architecture allows for integrating contextual information from heterogeneous sources. We evaluate context extracted from structured knowledge sources and from prompting large language models. Our approach is able to outperform competitive baselines (1.9pp on average) on a large and diverse stance detection benchmark, both (1) in-domain, i.e. for seen targets, and (2) out-of-domain, i.e. for targets unseen during training. Our analysis shows that it is able to regularize for spurious label correlations with target-speci\ufb01c cue words 1 ."
}