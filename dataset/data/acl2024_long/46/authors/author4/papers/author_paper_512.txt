{
    "id": "b503f386f3da13f059b654d77e7ca36ff6ae11ca",
    "title": "Table of Contents Named Entity Recognition in Wikipedia Wiktionary for Natural Language Processing: Methodology and Limitations Using the Wiktionary Graph Structure for Synonym Detection Evaluating a Statistical Ccg Parser on Wikipedia Acquiring High Quality Non-expert Knowledge from On-demand Workf",
    "abstract": "Order copies of this and other ACL proceedings from: ii Preface Welcome to the proceedings of the ACL Workshop \" The People's Web Meets NLP: Collaboratively Constructed Semantic Resources \". The workshop attracted 21 submissions, of which 9 are included in these proceedings. We are gratified by this level of interest. This workshop was motivated by the observation that the NLP community is currently considerably influenced by online resources, which are collaboratively constructed by ordinary users on the Web. In many works, such resources have been used as semantic resources overcoming the knowledge acquisition bottleneck and coverage problems pertinent to conventional lexical semantic resources. The resource that has gained the greatest popularity in this respect so far is Wikipedia. However, the scope of the workshop deliberately exceeded Wikipedia. We are happy that the proceedings include papers on resources such as Wiktionary, Mechanical Turk, or creating semantic resources through online games. This encourages us in our belief that collaboratively constructed semantic resources are of growing interest for the natural language processing community. We should also add that we hoped to bring together researchers from both worlds: those using collaboratively created resources in NLP applications and those using NLP applications for improving the resources or extracting different types of semantic information from them. This is also reflected in the proceedings, although the stronger interest was taken in using semantic resources for NLP applications. Abstract Gazetteers or entity dictionaries are important knowledge resources for solving a wide range of NLP problems, such as entity extraction. We introduce a novel method to automatically generate gazetteers from seed lists using an external knowledge resource, the Wikipedia. Unlike previous methods, our method exploits the rich content and various structural elements of Wikipe-dia, and does not rely on language-or domain-specific knowledge. Furthermore, applying the extended gazetteers to an entity extraction task in a scientific domain, we empirically observed a significant improvement in system accuracy when compared with those using seed gazetteers."
}