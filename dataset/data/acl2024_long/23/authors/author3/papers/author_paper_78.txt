{
    "id": "4b8da8de286e7e1f997878915389f8abfc892ce1",
    "title": "MELM: Data Augmentation with Masked Entity Language Modeling for Cross-lingual NER",
    "abstract": "Data augmentation for cross-lingual NER requires \ufb01ne-grained control over token labels of the augmented text. Existing augmentation approach based on masked language modeling may replace a labeled entity with words of a different class, which makes the augmented sentence incompatible with the original label sequence, and thus hurts the performance. We propose a data augmentation framework with Masked-Entity Language Modeling (MELM) which effectively ensures the replacing entities \ufb01t the original labels. Speci\ufb01cally, MELM lin-earizes NER labels into sentence context, and thus the \ufb01ne-tuned MELM is able to predict masked tokens by explicitly conditioning on their labels. Our MELM is agnostic to the source of data to be augmented. Speci\ufb01cally, when MELM is applied to augment training data of the source language, it achieves up to 3.5% F1 score improvement for cross-lingual NER. When unlabeled target data is available and MELM can be further applied to augment pseudo-labeled target data, the performance gain reaches 5.7%. Moreover, MELM consistently outperforms multiple baseline methods for data augmentation."
}