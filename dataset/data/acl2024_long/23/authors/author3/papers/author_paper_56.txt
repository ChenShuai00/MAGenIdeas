{
    "id": "714beceee04a4ab07a971ff69961972b2e740eb5",
    "title": "Is GPT-3 a Psychopath? Evaluating Large Language Models from a Psychological Perspective",
    "abstract": "Are large language models (LLMs) like GPT-3 psychologically safe? In this work, we de-sign unbiased prompts to evaluate LLMs systematically from a psychological perspective. Firstly, we test the personality traits of three different LLMs with Short Dark Triad (SD-3) and Big Five Inventory (BFI). We \ufb01nd all of them show higher scores on SD-3 than the human average, indicating a relatively darker personality. Furthermore, LLMs like Instruct-GPT and FLAN-T5, which are \ufb01ne-tuned with safety metrics, do not necessarily have more positive personalities. They score higher on Machiavellianism and Narcissism than GPT-3. Secondly, we test the LLMs in GPT-3 series on well-being tests to study the impact of \ufb01ne-tuning with more training data. Interestingly, we observe a continuous increase in well-being scores from GPT-3 to Instruct-GPT. Following the observations, we show that instruction-\ufb01netune FLAN-T5 with positive answers in BFI can effectively improve the model from a psychological perspective. Finally, we call on the community to evaluate and improve LLMs\u2019 safety systematically instead of at the sentence level only."
}