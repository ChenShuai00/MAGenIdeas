{
    "id": "9c9fafc3105325428fe6f6ef58709be433510b2f",
    "title": "Better Robustness by More Coverage: Adversarial Training with Mixup Augmentation for Robust Fine-tuning",
    "abstract": "Pre-trained language models (PLMs) fail mis-erably on adversarial attacks. To improve the robustness, adversarial data augmentation (ADA) has been widely adopted, which attempts to cover more search space of adversarial attacks by adding the adversarial examples during training. However, the number of adversarial examples added by ADA is extremely insuf\ufb01cient due to the enormously large search space. In this work, we propose a simple and effective method to cover much larger proportion of the attack search space, called Adversarial Data Augmentation with Mixup (Mix-ADA). Speci\ufb01cally, MixADA linearly interpolates the representations of pairs of training examples to form new virtual samples, which are more abundant and diverse than the discrete adversarial examples used in conventional ADA. Moreover, to evaluate the robustness of different models fairly, we adopt a challenging setup, which dynamically generates new adversarial examples for each model. In the text classi\ufb01cation experiments of BERT and RoBERTa, MixADA achieves signi\ufb01cant robustness gains under two strong adversarial attacks and alleviates the performance degradation of ADA on the original data. Our"
}