{
    "id": "be24365f7bf8138cd0d4eab501ae2c107d34af31",
    "title": "Journal of Chromatography A",
    "abstract": "The retention time (RT) is a crucial source of data for liquid chromatography-mass spectrometry (LCMS). A model that can accurately predict the RT for each molecule would empower \ufb01ltering candidates with similar spectra but di\ufb00ering RT in LCMS-based molecule identi\ufb01cation. Recent research shows that graph neural networks (GNNs) outperform traditional machine learning algorithms in RT prediction. However, all of these models use relatively shallow GNNs. This study for the \ufb01rst time investigates how depth a\ufb00ects GNNs\u2019 performance on RT prediction. The results demonstrate that a notable improvement can be achieved by pushing the depth of GNNs to 16 layers by the adoption of residual connection. Additionally, we also \ufb01nd that graph convolutional network (GCN) model bene\ufb01ts from the edge information. The developed deep graph convolutional network, DeepGCN-RT, signi\ufb01cantly outperforms the previous state-of-the-art method and achieves the lowest mean absolute percentage error (MAPE) of 3.3% and the lowest mean absolute error (MAE) of 26.55 s on the SMRT test set. We also \ufb01netune DeepGCN-RT on seven datasets with various chromatographic conditions. The mean MAE of the seven datasets largely decreases 30% compared to previous state-of-the-art method. On the RIKEN-PlaSMA dataset, we also test the e\ufb00ectiveness of DeepGCN-RT in assisting molecular structure identi\ufb01cation. By 30% lessening the number of potential structures, DeepGCN-RT is able to improve top-1 accuracy by about 11%."
}