{
    "id": "7852d0152dc5f335dd753c76ce14dbbb92cb66c9",
    "title": "PAELLA : Parameter-Efficient Lightweight Language-Agnostic Captioning Model",
    "abstract": "We introduce PAELLA, a Pa rameter-E fficient 001 L ightweight L anguage-A gnostic image cap-002 tioning model that uses retrieval augmenta-003 tion to perform multilingual caption genera-004 tion. The model is trained by learning a small 005 mapping network with 30M parameters be-006 tween a pre-trained visual model and a mul-007 tilingual language model that is conditioned 008 on two types of input: (i) the image itself, 009 and (ii) a set of retrieved captions in the tar-010 get language. The retrieved examples play 011 a key role in guiding the model to generate 012 captions across languages. Compared to other 013 multilingual captioning models, PAELLA can 014 be trained in one day on a single GPU. The 015 model is lightweight in terms of the number 016 of trainable parameters, which only exist in its 017 mapping network, and also in the amount of 018 multilingual training data that is required. Ex-019 periments on the XM3600 dataset, featuring 36 020 languages, show that PAELLA can outperform 021 or compete against some models with 4\u201387 \u00d7 022 more learned parameters and 35\u2013863 \u00d7 more 023 data. We also find that PAELLA can be trained 024 on only monolingual data and still show strong 025 zero-shot abilities in other languages. 026"
}